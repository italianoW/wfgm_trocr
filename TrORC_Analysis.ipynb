{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"changheonkim/iam-trocr\")\n",
        "path = Path(path)/\"IAM\"\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxTJVBG-U6yK",
        "outputId": "599653ec-d04f-4f53-f4b9-4f8b82d0e36d"
      },
      "id": "hxTJVBG-U6yK",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'iam-trocr' dataset.\n",
            "Path to dataset files: /kaggle/input/iam-trocr/IAM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Assuming 'path' variable holds the base directory from kagglehub.dataset_download\n",
        "# If not, please replace 'path' with the correct directory string, e.g., '/content/IAM'\n",
        "if 'path' in globals():\n",
        "    print(f\"Listing directories in: {path}\")\n",
        "    # Use a shell command to list only directories recursively, and sort them\n",
        "    !ls {path/\"image\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm1FdFEtU9BU",
        "outputId": "db0badca-3813-43a8-b03f-d70b125dfdab"
      },
      "id": "Gm1FdFEtU9BU",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing directories in: /kaggle/input/iam-trocr/IAM\n",
            "c04-110-00.jpg\te06-070-02.jpg\t g07-000b-00.jpg  n02-157-05.jpg\n",
            "c04-110-01.jpg\te06-070-03.jpg\t g07-000b-01.jpg  n02-157-06.jpg\n",
            "c04-110-02.jpg\te06-070-04.jpg\t g07-000b-02.jpg  n02-157-07.jpg\n",
            "c04-110-03.jpg\te06-070-05.jpg\t g07-000b-03.jpg  n02-157-08.jpg\n",
            "c04-116-00.jpg\te06-070-06.jpg\t g07-000b-04.jpg  n03-038-00.jpg\n",
            "c04-116-01.jpg\te06-070-07.jpg\t g07-000b-05.jpg  n03-038-01.jpg\n",
            "c04-116-02.jpg\te06-070-08.jpg\t g07-000b-06.jpg  n03-038-02.jpg\n",
            "c04-116-03.jpg\te06-070-09.jpg\t g07-000b-07.jpg  n03-038-03.jpg\n",
            "c04-134-00.jpg\tf04-032-00.jpg\t g07-000b-08.jpg  n03-038-04.jpg\n",
            "c04-134-01.jpg\tf04-032-01.jpg\t g07-000b-09.jpg  n03-038-05.jpg\n",
            "c04-134-02.jpg\tf04-032-02.jpg\t g07-079a-00.jpg  n03-038-06.jpg\n",
            "c04-134-03.jpg\tf04-032-03.jpg\t g07-079a-01.jpg  n03-064-00.jpg\n",
            "c04-134-04.jpg\tf04-032-04.jpg\t g07-079a-02.jpg  n03-064-01.jpg\n",
            "c04-134-05.jpg\tf04-032-05.jpg\t g07-079a-03.jpg  n03-064-02.jpg\n",
            "c04-134-06.jpg\tf04-032-06.jpg\t g07-079a-04.jpg  n03-064-03.jpg\n",
            "c04-139-00.jpg\tf04-032-07.jpg\t g07-079a-05.jpg  n03-064-04.jpg\n",
            "c04-139-01.jpg\tf04-032-08.jpg\t g07-079a-06.jpg  n03-064-05.jpg\n",
            "c04-139-02.jpg\tf04-032-09.jpg\t g07-079a-07.jpg  n03-066-00.jpg\n",
            "c04-139-03.jpg\tf04-035-00.jpg\t g07-079a-08.jpg  n03-066-01.jpg\n",
            "c04-139-04.jpg\tf04-035-01.jpg\t g07-079a-09.jpg  n03-066-02.jpg\n",
            "c04-139-05.jpg\tf04-035-02.jpg\t g07-079a-10.jpg  n03-066-03.jpg\n",
            "c04-139-06.jpg\tf04-035-03.jpg\t g07-079a-11.jpg  n03-066-04.jpg\n",
            "c04-144-00.jpg\tf04-035-04.jpg\t m01-049-00.jpg   n03-066-05.jpg\n",
            "c04-144-01.jpg\tf04-035-05.jpg\t m01-049-01.jpg   n03-066-06.jpg\n",
            "c04-144-02.jpg\tf04-039-00.jpg\t m01-049-02.jpg   n03-066-07.jpg\n",
            "c04-144-03.jpg\tf04-039-01.jpg\t m01-049-03.jpg   n03-097-00.jpg\n",
            "c04-144-04.jpg\tf04-039-02.jpg\t m01-049-04.jpg   n03-097-01.jpg\n",
            "c04-144-05.jpg\tf04-039-03.jpg\t m01-049-05.jpg   n03-097-02.jpg\n",
            "c04-144-06.jpg\tf04-039-04.jpg\t m01-049-06.jpg   n03-097-03.jpg\n",
            "c04-144-07.jpg\tf04-039-05.jpg\t m01-049-07.jpg   n03-097-04.jpg\n",
            "c04-150-00.jpg\tf04-039-06.jpg\t m01-049-08.jpg   n03-097-05.jpg\n",
            "c04-150-01.jpg\tf04-039-07.jpg\t m01-049-09.jpg   n03-097-06.jpg\n",
            "c04-150-02.jpg\tf04-039-08.jpg\t m01-049-10.jpg   n03-097-07.jpg\n",
            "c04-150-03.jpg\tf04-043-00.jpg\t m01-049-11.jpg   n03-097-08.jpg\n",
            "c04-150-04.jpg\tf04-043-01.jpg\t m01-060-00.jpg   n03-103-00.jpg\n",
            "c04-150-05.jpg\tf04-043-02.jpg\t m01-060-01.jpg   n03-103-01.jpg\n",
            "c04-150-06.jpg\tf04-043-03.jpg\t m01-060-02.jpg   n03-103-02.jpg\n",
            "c04-150-07.jpg\tf04-043-04.jpg\t m01-060-03.jpg   n03-103-03.jpg\n",
            "c04-165-00.jpg\tf04-043-05.jpg\t m01-060-04.jpg   n03-103-04.jpg\n",
            "c04-165-01.jpg\tf04-043-06.jpg\t m01-060-05.jpg   n03-103-05.jpg\n",
            "c04-165-02.jpg\tf04-043-07.jpg\t m01-060-06.jpg   n03-103-06.jpg\n",
            "c04-165-03.jpg\tf04-053-00.jpg\t m01-060-07.jpg   n03-103-07.jpg\n",
            "c04-165-04.jpg\tf04-053-01.jpg\t m01-079-00.jpg   n03-103-08.jpg\n",
            "c04-165-05.jpg\tf04-053-02.jpg\t m01-079-01.jpg   n03-103-09.jpg\n",
            "c04-165-06.jpg\tf04-053-03.jpg\t m01-079-02.jpg   n03-106-00.jpg\n",
            "c04-165-07.jpg\tf04-053-04.jpg\t m01-079-03.jpg   n03-106-01.jpg\n",
            "c04-165-08.jpg\tf04-053-05.jpg\t m01-079-04.jpg   n03-106-02.jpg\n",
            "c04-170-00.jpg\tf04-053-06.jpg\t m01-079-05.jpg   n03-106-03.jpg\n",
            "c04-170-01.jpg\tf04-057-00.jpg\t m01-079-06.jpg   n03-106-04.jpg\n",
            "c04-170-02.jpg\tf04-057-01.jpg\t m01-084-00.jpg   n03-106-05.jpg\n",
            "c04-170-03.jpg\tf04-057-02.jpg\t m01-084-01.jpg   n03-106-06.jpg\n",
            "c04-170-04.jpg\tf04-057-03.jpg\t m01-084-02.jpg   n03-106-07.jpg\n",
            "c06-011-00.jpg\tf04-057-04.jpg\t m01-084-03.jpg   n03-106-08.jpg\n",
            "c06-011-01.jpg\tf04-057-05.jpg\t m01-084-04.jpg   n03-106-09.jpg\n",
            "c06-011-02.jpg\tf04-057-06.jpg\t m01-084-05.jpg   n03-106-10.jpg\n",
            "c06-011-03.jpg\tf04-057-07.jpg\t m01-084-06.jpg   n03-106-11.jpg\n",
            "c06-011-04.jpg\tf04-057-08.jpg\t m01-084-07.jpg   n03-113-00.jpg\n",
            "c06-011-05.jpg\tf04-057-09.jpg\t m01-095-00.jpg   n03-113-01.jpg\n",
            "c06-011-06.jpg\tf04-061-00.jpg\t m01-095-01.jpg   n03-113-02.jpg\n",
            "c06-011-07.jpg\tf04-061-01.jpg\t m01-095-02.jpg   n03-113-03.jpg\n",
            "c06-011-08.jpg\tf04-061-02.jpg\t m01-095-03.jpg   n03-113-04.jpg\n",
            "d01-016-00.jpg\tf04-061-03.jpg\t m01-095-04.jpg   n03-113-05.jpg\n",
            "d01-016-01.jpg\tf04-061-04.jpg\t m01-095-05.jpg   n03-113-06.jpg\n",
            "d01-016-02.jpg\tf04-061-05.jpg\t m01-095-06.jpg   n03-113-07.jpg\n",
            "d01-016-03.jpg\tf04-061-06.jpg\t m01-095-07.jpg   n03-113-08.jpg\n",
            "d01-019-00.jpg\tf04-061-07.jpg\t m01-104-00.jpg   n03-113-09.jpg\n",
            "d01-019-01.jpg\tf04-064-00.jpg\t m01-104-01.jpg   n03-120-00.jpg\n",
            "d01-019-02.jpg\tf04-064-01.jpg\t m01-104-02.jpg   n03-120-01.jpg\n",
            "d01-019-03.jpg\tf04-064-02.jpg\t m01-104-03.jpg   n03-120-02.jpg\n",
            "d01-019-04.jpg\tf04-064-03.jpg\t m01-104-04.jpg   n03-120-03.jpg\n",
            "d01-019-05.jpg\tf04-064-04.jpg\t m01-104-05.jpg   n03-120-04.jpg\n",
            "d01-049-00.jpg\tf04-064-05.jpg\t m01-104-06.jpg   n03-120-05.jpg\n",
            "d01-049-01.jpg\tf04-064-06.jpg\t m01-104-07.jpg   n03-120-06.jpg\n",
            "d01-049-02.jpg\tf04-064-07.jpg\t m01-110-00.jpg   n03-120-07.jpg\n",
            "d01-049-03.jpg\tf04-064-08.jpg\t m01-110-01.jpg   n03-120-08.jpg\n",
            "d01-049-04.jpg\tf04-068-00.jpg\t m01-110-02.jpg   n03-120-09.jpg\n",
            "d01-049-05.jpg\tf04-068-01.jpg\t m01-110-03.jpg   n03-126-00.jpg\n",
            "d01-049-06.jpg\tf04-068-02.jpg\t m01-110-04.jpg   n03-126-01.jpg\n",
            "d01-049-07.jpg\tf04-068-03.jpg\t m01-110-05.jpg   n03-126-02.jpg\n",
            "d01-049-08.jpg\tf04-068-04.jpg\t m01-110-06.jpg   n03-126-03.jpg\n",
            "d01-052-00.jpg\tf04-068-05.jpg\t m01-110-07.jpg   n03-126-04.jpg\n",
            "d01-052-01.jpg\tf04-068-06.jpg\t m01-110-08.jpg   n04-000-00.jpg\n",
            "d01-052-02.jpg\tf04-068-07.jpg\t m01-110-09.jpg   n04-000-01.jpg\n",
            "d01-052-03.jpg\tf04-071-00.jpg\t m01-110-10.jpg   n04-000-02.jpg\n",
            "d01-052-04.jpg\tf04-071-01.jpg\t m01-110-11.jpg   n04-000-03.jpg\n",
            "d01-052-05.jpg\tf04-071-02.jpg\t m01-121-00.jpg   n04-000-04.jpg\n",
            "d01-052-06.jpg\tf04-071-03.jpg\t m01-121-01.jpg   n04-000-05.jpg\n",
            "d01-052-07.jpg\tf04-071-04.jpg\t m01-121-02.jpg   n04-009-00.jpg\n",
            "d01-080-00.jpg\tf04-071-05.jpg\t m01-121-03.jpg   n04-009-01.jpg\n",
            "d01-080-01.jpg\tf04-071-06.jpg\t m01-121-04.jpg   n04-009-02.jpg\n",
            "d01-080-02.jpg\tf04-071-07.jpg\t m01-121-05.jpg   n04-009-03.jpg\n",
            "d01-080-03.jpg\tf04-071-08.jpg\t m01-121-06.jpg   n04-009-04.jpg\n",
            "d01-080-04.jpg\tf04-071-09.jpg\t m01-121-07.jpg   n04-009-05.jpg\n",
            "d01-080-05.jpg\tf04-074-00.jpg\t m01-121-08.jpg   n04-009-06.jpg\n",
            "d01-080-06.jpg\tf04-074-01.jpg\t m01-125-00.jpg   n04-048-00.jpg\n",
            "d01-080-07.jpg\tf04-074-02.jpg\t m01-125-01.jpg   n04-048-01.jpg\n",
            "d01-085-00.jpg\tf04-074-03.jpg\t m01-125-02.jpg   n04-048-02.jpg\n",
            "d01-085-01.jpg\tf04-074-04.jpg\t m01-125-03.jpg   n04-048-03.jpg\n",
            "d01-085-02.jpg\tf04-074-05.jpg\t m01-125-04.jpg   n04-048-04.jpg\n",
            "d01-085-03.jpg\tf04-074-06.jpg\t m01-125-05.jpg   n04-048-05.jpg\n",
            "d01-085-04.jpg\tf04-074-07.jpg\t m01-125-06.jpg   n04-048-06.jpg\n",
            "d01-085-05.jpg\tf04-074-08.jpg\t m01-125-07.jpg   n04-048-07.jpg\n",
            "d01-085-06.jpg\tf04-074-09.jpg\t m01-125-08.jpg   n04-048-08.jpg\n",
            "d01-098-00.jpg\tf04-074-10.jpg\t m01-125-09.jpg   n04-048-09.jpg\n",
            "d01-098-01.jpg\tf04-074-11.jpg\t m01-125-10.jpg   n04-052-00.jpg\n",
            "d01-098-02.jpg\tf04-079-00.jpg\t m01-131-00.jpg   n04-052-01.jpg\n",
            "d01-098-03.jpg\tf04-079-01.jpg\t m01-131-01.jpg   n04-052-02.jpg\n",
            "d01-098-04.jpg\tf04-079-02.jpg\t m01-131-02.jpg   n04-052-03.jpg\n",
            "d01-098-05.jpg\tf04-079-03.jpg\t m01-131-03.jpg   n04-052-04.jpg\n",
            "d01-098-06.jpg\tf04-079-04.jpg\t m01-131-04.jpg   n04-052-05.jpg\n",
            "d01-098-07.jpg\tf04-079-05.jpg\t m01-131-05.jpg   n04-052-06.jpg\n",
            "d01-104-00.jpg\tf04-079-06.jpg\t m01-131-06.jpg   n04-052-07.jpg\n",
            "d01-104-01.jpg\tf04-079-07.jpg\t m01-136-00.jpg   n04-052-08.jpg\n",
            "d01-104-02.jpg\tf04-079-08.jpg\t m01-136-01.jpg   n04-060-00.jpg\n",
            "d01-104-03.jpg\tf04-079-09.jpg\t m01-136-02.jpg   n04-060-01.jpg\n",
            "d01-104-04.jpg\tf04-079-10.jpg\t m01-136-03.jpg   n04-060-02.jpg\n",
            "d01-104-05.jpg\tf04-083-00.jpg\t m01-136-04.jpg   n04-060-03.jpg\n",
            "d01-104-06.jpg\tf04-083-01.jpg\t m01-136-05.jpg   n04-060-04.jpg\n",
            "d01-104-07.jpg\tf04-083-02.jpg\t m01-136-06.jpg   n04-060-05.jpg\n",
            "d01-104-08.jpg\tf04-083-03.jpg\t m01-136-07.jpg   n04-060-06.jpg\n",
            "d01-118-00.jpg\tf04-083-04.jpg\t m01-136-08.jpg   n04-068-00.jpg\n",
            "d01-118-01.jpg\tf04-083-05.jpg\t m01-136-09.jpg   n04-068-01.jpg\n",
            "d01-118-02.jpg\tf04-083-06.jpg\t m01-136-10.jpg   n04-068-02.jpg\n",
            "d01-118-03.jpg\tf04-083-07.jpg\t m01-149-00.jpg   n04-068-03.jpg\n",
            "d01-118-04.jpg\tf04-083-08.jpg\t m01-149-01.jpg   n04-068-04.jpg\n",
            "d01-118-05.jpg\tf04-083-09.jpg\t m01-149-02.jpg   n04-068-05.jpg\n",
            "d01-118-06.jpg\tf04-087-00.jpg\t m01-149-03.jpg   n04-068-06.jpg\n",
            "d01-123-00.jpg\tf04-087-01.jpg\t m01-149-04.jpg   n04-068-07.jpg\n",
            "d01-123-01.jpg\tf04-087-02.jpg\t m01-149-05.jpg   n04-075-00.jpg\n",
            "d01-123-02.jpg\tf04-087-03.jpg\t m01-149-06.jpg   n04-075-01.jpg\n",
            "d01-123-03.jpg\tf04-087-04.jpg\t m01-149-07.jpg   n04-075-02.jpg\n",
            "d01-123-04.jpg\tf04-087-05.jpg\t m02-048-00.jpg   n04-075-03.jpg\n",
            "d01-123-05.jpg\tf07-000-00.jpg\t m02-048-01.jpg   n04-075-04.jpg\n",
            "d01-123-06.jpg\tf07-000-01.jpg\t m02-048-02.jpg   n04-075-05.jpg\n",
            "d01-123-07.jpg\tf07-000-02.jpg\t m02-048-03.jpg   n04-075-06.jpg\n",
            "d03-117-00.jpg\tf07-000-03.jpg\t m02-048-04.jpg   n04-075-07.jpg\n",
            "d03-117-01.jpg\tf07-000-04.jpg\t m02-048-05.jpg   n04-084-00.jpg\n",
            "d03-117-02.jpg\tf07-000-05.jpg\t m02-048-06.jpg   n04-084-01.jpg\n",
            "d03-117-03.jpg\tf07-000-06.jpg\t m02-048-07.jpg   n04-084-02.jpg\n",
            "d03-117-04.jpg\tf07-000-07.jpg\t m02-048-08.jpg   n04-084-03.jpg\n",
            "d03-117-05.jpg\tf07-000-08.jpg\t m02-048-09.jpg   n04-084-04.jpg\n",
            "d03-117-06.jpg\tf07-000b-00.jpg  m02-048-10.jpg   n04-084-05.jpg\n",
            "d03-117-07.jpg\tf07-000b-01.jpg  m02-055-00.jpg   n04-084-06.jpg\n",
            "d03-117-08.jpg\tf07-000b-02.jpg  m02-055-01.jpg   n04-092-00.jpg\n",
            "d04-012-00.jpg\tf07-000b-03.jpg  m02-055-02.jpg   n04-092-01.jpg\n",
            "d04-012-01.jpg\tf07-000b-04.jpg  m02-055-03.jpg   n04-092-02.jpg\n",
            "d04-012-02.jpg\tf07-000b-05.jpg  m02-055-04.jpg   n04-092-03.jpg\n",
            "d04-012-03.jpg\tf07-000b-06.jpg  m02-055-05.jpg   n04-092-04.jpg\n",
            "d04-012-04.jpg\tf07-002-00.jpg\t m02-055-06.jpg   n04-092-05.jpg\n",
            "d04-012-05.jpg\tf07-002-01.jpg\t m02-055-07.jpg   n04-092-06.jpg\n",
            "d04-012-06.jpg\tf07-002-02.jpg\t m02-055-08.jpg   n04-092-07.jpg\n",
            "d04-012-07.jpg\tf07-002-03.jpg\t m02-055-09.jpg   n04-092-08.jpg\n",
            "d04-012-08.jpg\tf07-002-04.jpg\t m02-055-10.jpg   n04-100-00.jpg\n",
            "d04-012-09.jpg\tf07-002-05.jpg\t m02-059-00.jpg   n04-100-01.jpg\n",
            "d04-012-10.jpg\tf07-002-06.jpg\t m02-059-01.jpg   n04-100-02.jpg\n",
            "d04-016-00.jpg\tf07-002-07.jpg\t m02-059-02.jpg   n04-100-03.jpg\n",
            "d04-016-01.jpg\tf07-002-08.jpg\t m02-059-03.jpg   n04-100-04.jpg\n",
            "d04-016-02.jpg\tf07-006-00.jpg\t m02-059-04.jpg   n04-100-05.jpg\n",
            "d04-016-03.jpg\tf07-006-01.jpg\t m02-059-05.jpg   n04-100-06.jpg\n",
            "d04-016-04.jpg\tf07-006-02.jpg\t m02-059-06.jpg   n04-100-07.jpg\n",
            "d04-016-05.jpg\tf07-006-03.jpg\t m02-066-00.jpg   n04-107-00.jpg\n",
            "d04-016-06.jpg\tf07-006-04.jpg\t m02-066-01.jpg   n04-107-01.jpg\n",
            "d04-016-07.jpg\tf07-006-05.jpg\t m02-066-02.jpg   n04-107-02.jpg\n",
            "d04-016-08.jpg\tf07-006-06.jpg\t m02-066-03.jpg   n04-107-03.jpg\n",
            "d04-021-00.jpg\tf07-009-00.jpg\t m02-066-04.jpg   n04-107-04.jpg\n",
            "d04-021-01.jpg\tf07-009-01.jpg\t m02-066-05.jpg   n04-107-05.jpg\n",
            "d04-021-02.jpg\tf07-009-02.jpg\t m02-069-00.jpg   n04-107-06.jpg\n",
            "d04-021-03.jpg\tf07-009-03.jpg\t m02-069-01.jpg   n04-107-07.jpg\n",
            "d04-021-04.jpg\tf07-009-04.jpg\t m02-069-02.jpg   n04-107-08.jpg\n",
            "d04-021-05.jpg\tf07-009-05.jpg\t m02-069-03.jpg   n04-114-00.jpg\n",
            "d04-021-06.jpg\tf07-009-06.jpg\t m02-069-04.jpg   n04-114-01.jpg\n",
            "d04-021-07.jpg\tf07-009-07.jpg\t m02-069-05.jpg   n04-114-02.jpg\n",
            "d04-028-00.jpg\tf07-009-08.jpg\t m02-069-06.jpg   n04-114-03.jpg\n",
            "d04-028-01.jpg\tf07-009-09.jpg\t m02-069-07.jpg   n04-114-04.jpg\n",
            "d04-028-02.jpg\tf07-013-00.jpg\t m02-069-08.jpg   n04-114-05.jpg\n",
            "d04-028-03.jpg\tf07-013-01.jpg\t m02-072-00.jpg   n04-114-06.jpg\n",
            "d04-028-04.jpg\tf07-013-02.jpg\t m02-072-01.jpg   n04-114-07.jpg\n",
            "d04-028-05.jpg\tf07-013-03.jpg\t m02-072-02.jpg   n04-114-08.jpg\n",
            "d04-028-06.jpg\tf07-013-04.jpg\t m02-072-03.jpg   n04-130-00.jpg\n",
            "d04-032-00.jpg\tf07-013-05.jpg\t m02-072-04.jpg   n04-130-01.jpg\n",
            "d04-032-01.jpg\tf07-013-06.jpg\t m02-072-05.jpg   n04-130-02.jpg\n",
            "d04-032-02.jpg\tf07-013-07.jpg\t m02-072-06.jpg   n04-130-03.jpg\n",
            "d04-032-03.jpg\tf07-013-08.jpg\t m02-080-00.jpg   n04-130-04.jpg\n",
            "d04-032-04.jpg\tf07-013-09.jpg\t m02-080-01.jpg   n04-130-05.jpg\n",
            "d04-032-05.jpg\tf07-013-10.jpg\t m02-080-02.jpg   n04-139-00.jpg\n",
            "d04-032-06.jpg\tf07-016-00.jpg\t m02-080-03.jpg   n04-139-01.jpg\n",
            "d04-032-07.jpg\tf07-016-01.jpg\t m02-080-04.jpg   n04-139-02.jpg\n",
            "d04-032-08.jpg\tf07-016-02.jpg\t m02-080-05.jpg   n04-139-03.jpg\n",
            "d04-032-09.jpg\tf07-016-03.jpg\t m02-080-06.jpg   n04-139-04.jpg\n",
            "d04-032-10.jpg\tf07-016-04.jpg\t m02-080-07.jpg   n04-139-05.jpg\n",
            "d04-037-00.jpg\tf07-016-05.jpg\t m02-080-08.jpg   n04-139-06.jpg\n",
            "d04-037-01.jpg\tf07-016-06.jpg\t m02-080-09.jpg   n04-139-07.jpg\n",
            "d04-037-02.jpg\tf07-016-07.jpg\t m02-087-00.jpg   n04-139-08.jpg\n",
            "d04-037-03.jpg\tf07-016-08.jpg\t m02-087-01.jpg   n04-149-00.jpg\n",
            "d04-037-04.jpg\tf07-016-09.jpg\t m02-087-02.jpg   n04-149-01.jpg\n",
            "d04-037-05.jpg\tf07-016-10.jpg\t m02-087-03.jpg   n04-149-02.jpg\n",
            "d04-037-06.jpg\tf07-019a-00.jpg  m02-087-04.jpg   n04-149-03.jpg\n",
            "d04-047-00.jpg\tf07-019a-01.jpg  m02-087-05.jpg   n04-149-04.jpg\n",
            "d04-047-01.jpg\tf07-019a-02.jpg  m02-087-06.jpg   n04-149-05.jpg\n",
            "d04-047-02.jpg\tf07-019a-03.jpg  m02-087-07.jpg   n04-149-06.jpg\n",
            "d04-047-03.jpg\tf07-019a-04.jpg  m02-095-00.jpg   n04-149-07.jpg\n",
            "d04-047-04.jpg\tf07-019a-05.jpg  m02-095-01.jpg   n04-156-00.jpg\n",
            "d04-047-05.jpg\tf07-019a-06.jpg  m02-095-02.jpg   n04-156-01.jpg\n",
            "d04-047-06.jpg\tf07-019a-07.jpg  m02-095-03.jpg   n04-156-02.jpg\n",
            "d04-047-07.jpg\tf07-019a-08.jpg  m02-095-04.jpg   n04-156-03.jpg\n",
            "d04-047-08.jpg\tf07-019b-00.jpg  m02-095-05.jpg   n04-156-04.jpg\n",
            "d04-050-00.jpg\tf07-019b-01.jpg  m02-095-06.jpg   n04-156-05.jpg\n",
            "d04-050-01.jpg\tf07-019b-02.jpg  m02-095-07.jpg   n04-156-06.jpg\n",
            "d04-050-02.jpg\tf07-019b-03.jpg  m02-095-08.jpg   n04-156-07.jpg\n",
            "d04-050-03.jpg\tf07-019b-04.jpg  m02-095-09.jpg   n04-163-00.jpg\n",
            "d04-050-04.jpg\tf07-019b-05.jpg  m02-109-00.jpg   n04-163-01.jpg\n",
            "d04-050-05.jpg\tf07-019b-06.jpg  m02-109-01.jpg   n04-163-02.jpg\n",
            "d04-053-00.jpg\tf07-019b-07.jpg  m02-109-02.jpg   n04-163-03.jpg\n",
            "d04-053-01.jpg\tf07-019b-08.jpg  m02-109-03.jpg   n04-163-04.jpg\n",
            "d04-053-02.jpg\tf07-019b-09.jpg  m02-109-04.jpg   n04-163-05.jpg\n",
            "d04-053-03.jpg\tf07-019b-10.jpg  m02-109-05.jpg   n04-163-06.jpg\n",
            "d04-053-04.jpg\tf07-021a-00.jpg  m02-109-06.jpg   n04-163-07.jpg\n",
            "d04-053-05.jpg\tf07-021a-01.jpg  m02-109-07.jpg   n04-163-08.jpg\n",
            "d04-053-06.jpg\tf07-021a-02.jpg  m02-109-08.jpg   n04-202-00.jpg\n",
            "d04-053-07.jpg\tf07-021a-03.jpg  m02-112-00.jpg   n04-202-01.jpg\n",
            "d04-053-08.jpg\tf07-021a-04.jpg  m02-112-01.jpg   n04-202-02.jpg\n",
            "d04-053-09.jpg\tf07-021a-05.jpg  m02-112-02.jpg   n04-202-03.jpg\n",
            "d04-053-10.jpg\tf07-021a-06.jpg  m02-112-03.jpg   n04-202-04.jpg\n",
            "d04-058-00.jpg\tf07-021a-07.jpg  m02-112-04.jpg   n04-202-05.jpg\n",
            "d04-058-01.jpg\tf07-021b-00.jpg  m02-112-05.jpg   n04-202-06.jpg\n",
            "d04-058-02.jpg\tf07-021b-01.jpg  m03-006-00.jpg   n04-202-07.jpg\n",
            "d04-058-03.jpg\tf07-021b-02.jpg  m03-006-01.jpg   n04-202-08.jpg\n",
            "d04-058-04.jpg\tf07-021b-03.jpg  m03-006-02.jpg   n04-209-00.jpg\n",
            "d04-058-05.jpg\tf07-021b-04.jpg  m03-006-03.jpg   n04-209-01.jpg\n",
            "d04-058-06.jpg\tf07-021b-05.jpg  m03-006-04.jpg   n04-209-02.jpg\n",
            "d04-062-00.jpg\tf07-021b-06.jpg  m03-006-05.jpg   n04-209-03.jpg\n",
            "d04-062-01.jpg\tf07-021b-07.jpg  m03-006-06.jpg   n04-209-04.jpg\n",
            "d04-062-02.jpg\tf07-021b-08.jpg  m03-006-07.jpg   n04-209-05.jpg\n",
            "d04-062-03.jpg\tf07-021b-09.jpg  m03-006-08.jpg   n04-209-06.jpg\n",
            "d04-062-04.jpg\tf07-024a-00.jpg  m03-006-09.jpg   n04-209-07.jpg\n",
            "d04-066-00.jpg\tf07-024a-01.jpg  m03-013-00.jpg   n04-213-00.jpg\n",
            "d04-066-01.jpg\tf07-024a-02.jpg  m03-013-01.jpg   n04-213-01.jpg\n",
            "d04-066-02.jpg\tf07-024a-03.jpg  m03-013-02.jpg   n04-213-02.jpg\n",
            "d04-066-03.jpg\tf07-024a-04.jpg  m03-013-03.jpg   n04-213-03.jpg\n",
            "d04-066-04.jpg\tf07-024a-05.jpg  m03-013-04.jpg   n04-213-04.jpg\n",
            "d04-066-05.jpg\tf07-024a-06.jpg  m03-013-05.jpg   n04-213-05.jpg\n",
            "d04-066-06.jpg\tf07-024a-07.jpg  m03-013-06.jpg   n04-213-06.jpg\n",
            "d04-066-07.jpg\tf07-024a-08.jpg  m03-020-00.jpg   n04-213-07.jpg\n",
            "d04-066-08.jpg\tf07-024b-00.jpg  m03-020-01.jpg   n04-218-00.jpg\n",
            "d04-066-09.jpg\tf07-024b-01.jpg  m03-020-02.jpg   n04-218-01.jpg\n",
            "d04-086-00.jpg\tf07-024b-02.jpg  m03-020-03.jpg   n04-218-02.jpg\n",
            "d04-086-01.jpg\tf07-024b-03.jpg  m03-020-04.jpg   n04-218-03.jpg\n",
            "d04-086-02.jpg\tf07-024b-04.jpg  m03-020-05.jpg   n04-218-04.jpg\n",
            "d04-086-03.jpg\tf07-024b-05.jpg  m03-033-00.jpg   n04-218-05.jpg\n",
            "d04-086-04.jpg\tf07-024b-06.jpg  m03-033-01.jpg   n04-218-06.jpg\n",
            "d04-086-05.jpg\tf07-024b-07.jpg  m03-033-02.jpg   n04-218-07.jpg\n",
            "d04-086-06.jpg\tf07-024b-08.jpg  m03-033-03.jpg   n04-218-08.jpg\n",
            "d04-089-00.jpg\tf07-024b-09.jpg  m03-033-04.jpg   n04-218-09.jpg\n",
            "d04-089-01.jpg\tf07-024b-10.jpg  m03-033-05.jpg   n06-074-00.jpg\n",
            "d04-089-02.jpg\tf07-028a-00.jpg  m03-033-06.jpg   n06-074-01.jpg\n",
            "d04-089-03.jpg\tf07-028a-01.jpg  m03-033-07.jpg   n06-074-02.jpg\n",
            "d04-089-04.jpg\tf07-028a-02.jpg  m03-110-00.jpg   n06-074-03.jpg\n",
            "d04-089-05.jpg\tf07-028a-03.jpg  m03-110-01.jpg   n06-074-04.jpg\n",
            "d04-089-06.jpg\tf07-028a-04.jpg  m03-110-02.jpg   n06-074-05.jpg\n",
            "d04-089-07.jpg\tf07-028a-05.jpg  m03-110-03.jpg   n06-074-06.jpg\n",
            "d04-096-00.jpg\tf07-028a-06.jpg  m03-110-04.jpg   n06-082-00.jpg\n",
            "d04-096-01.jpg\tf07-028a-07.jpg  m03-110-05.jpg   n06-082-01.jpg\n",
            "d04-096-02.jpg\tf07-028a-08.jpg  m03-110-06.jpg   n06-082-02.jpg\n",
            "d04-096-03.jpg\tf07-028a-09.jpg  m03-110-07.jpg   n06-082-03.jpg\n",
            "d04-096-04.jpg\tf07-032a-00.jpg  m03-110-08.jpg   n06-082-04.jpg\n",
            "d04-096-05.jpg\tf07-032a-01.jpg  m03-110-09.jpg   n06-082-05.jpg\n",
            "d04-096-06.jpg\tf07-032a-02.jpg  m03-114-00.jpg   n06-082-06.jpg\n",
            "d04-096-07.jpg\tf07-032a-03.jpg  m03-114-01.jpg   n06-082-07.jpg\n",
            "d04-101-00.jpg\tf07-032a-04.jpg  m03-114-02.jpg   n06-092-00.jpg\n",
            "d04-101-01.jpg\tf07-032a-05.jpg  m03-114-03.jpg   n06-092-01.jpg\n",
            "d04-101-02.jpg\tf07-032a-06.jpg  m03-114-04.jpg   n06-092-02.jpg\n",
            "d04-101-03.jpg\tf07-032a-07.jpg  m03-114-05.jpg   n06-092-03.jpg\n",
            "d04-101-04.jpg\tf07-032a-08.jpg  m03-114-06.jpg   n06-092-04.jpg\n",
            "d04-101-05.jpg\tf07-032a-09.jpg  m03-114-07.jpg   n06-092-05.jpg\n",
            "d04-111-00.jpg\tf07-032a-10.jpg  m03-114-08.jpg   n06-092-06.jpg\n",
            "d04-111-01.jpg\tf07-039a-00.jpg  m03-114-09.jpg   n06-092-07.jpg\n",
            "d04-111-02.jpg\tf07-039a-01.jpg  m03-118-00.jpg   n06-092-08.jpg\n",
            "d04-111-03.jpg\tf07-039a-02.jpg  m03-118-01.jpg   n06-100-00.jpg\n",
            "d04-111-04.jpg\tf07-039a-03.jpg  m03-118-02.jpg   n06-100-01.jpg\n",
            "d04-111-05.jpg\tf07-039a-04.jpg  m03-118-03.jpg   n06-100-02.jpg\n",
            "d04-111-06.jpg\tf07-039a-05.jpg  m03-118-04.jpg   n06-100-03.jpg\n",
            "d04-111-07.jpg\tf07-039a-06.jpg  m03-118-05.jpg   n06-100-04.jpg\n",
            "d04-111-08.jpg\tf07-042a-00.jpg  m04-030-00.jpg   n06-100-05.jpg\n",
            "d04-111-09.jpg\tf07-042a-01.jpg  m04-030-01.jpg   n06-100-06.jpg\n",
            "d04-111-10.jpg\tf07-042a-02.jpg  m04-030-02.jpg   n06-100-07.jpg\n",
            "d04-111-11.jpg\tf07-042a-03.jpg  m04-030-03.jpg   n06-100-08.jpg\n",
            "d04-125-00.jpg\tf07-042a-04.jpg  m04-030-04.jpg   n06-100-09.jpg\n",
            "d04-125-01.jpg\tf07-042a-05.jpg  m04-038-00.jpg   n06-111-00.jpg\n",
            "d04-125-02.jpg\tf07-042a-06.jpg  m04-038-01.jpg   n06-111-01.jpg\n",
            "d04-125-03.jpg\tf07-042a-07.jpg  m04-038-02.jpg   n06-111-02.jpg\n",
            "d04-125-04.jpg\tf07-046a-00.jpg  m04-038-03.jpg   n06-111-03.jpg\n",
            "d04-125-05.jpg\tf07-046a-01.jpg  m04-038-04.jpg   n06-111-04.jpg\n",
            "d04-131-00.jpg\tf07-046a-02.jpg  m04-038-05.jpg   n06-111-05.jpg\n",
            "d04-131-01.jpg\tf07-046a-03.jpg  m04-043-00.jpg   n06-111-06.jpg\n",
            "d04-131-02.jpg\tf07-046a-04.jpg  m04-043-01.jpg   n06-111-07.jpg\n",
            "d04-131-03.jpg\tf07-046a-05.jpg  m04-043-02.jpg   n06-119-00.jpg\n",
            "d04-131-04.jpg\tf07-046a-06.jpg  m04-043-03.jpg   n06-119-01.jpg\n",
            "d04-131-05.jpg\tf07-046a-07.jpg  m04-043-04.jpg   n06-119-02.jpg\n",
            "d04-131-06.jpg\tf07-046a-08.jpg  m04-061-00.jpg   n06-119-03.jpg\n",
            "d05-008-00.jpg\tf07-046a-09.jpg  m04-061-01.jpg   n06-119-04.jpg\n",
            "d05-008-01.jpg\tf07-069-00.jpg\t m04-061-02.jpg   n06-119-05.jpg\n",
            "d05-008-02.jpg\tf07-069-01.jpg\t m04-061-03.jpg   n06-119-06.jpg\n",
            "d05-008-03.jpg\tf07-069-02.jpg\t m04-061-04.jpg   n06-123-00.jpg\n",
            "d05-008-04.jpg\tf07-069-03.jpg\t m04-072-00.jpg   n06-123-01.jpg\n",
            "d05-008-05.jpg\tf07-069-04.jpg\t m04-072-01.jpg   n06-123-02.jpg\n",
            "d05-008-06.jpg\tf07-069-05.jpg\t m04-072-02.jpg   n06-123-03.jpg\n",
            "d05-008-07.jpg\tf07-069-06.jpg\t m04-072-03.jpg   n06-123-04.jpg\n",
            "d05-013-00.jpg\tf07-069-07.jpg\t m04-072-04.jpg   n06-123-05.jpg\n",
            "d05-013-01.jpg\tf07-069-08.jpg\t m04-072-05.jpg   n06-123-06.jpg\n",
            "d05-013-02.jpg\tf07-069-09.jpg\t m04-072-06.jpg   n06-123-07.jpg\n",
            "d05-013-03.jpg\tf07-073-00.jpg\t m04-072-07.jpg   n06-123-08.jpg\n",
            "d05-013-04.jpg\tf07-073-01.jpg\t m04-072-08.jpg   n06-123-09.jpg\n",
            "d05-013-05.jpg\tf07-073-02.jpg\t m04-072-09.jpg   n06-123-10.jpg\n",
            "d05-013-06.jpg\tf07-073-03.jpg\t m04-072-10.jpg   n06-128-00.jpg\n",
            "d05-013-07.jpg\tf07-073-04.jpg\t m04-078-00.jpg   n06-128-01.jpg\n",
            "d05-013-08.jpg\tf07-073-05.jpg\t m04-078-01.jpg   n06-128-02.jpg\n",
            "d05-021-00.jpg\tf07-073-06.jpg\t m04-078-02.jpg   n06-128-03.jpg\n",
            "d05-021-01.jpg\tf07-073-07.jpg\t m04-078-03.jpg   n06-128-04.jpg\n",
            "d05-021-02.jpg\tf07-073-08.jpg\t m04-078-04.jpg   n06-128-05.jpg\n",
            "d05-021-03.jpg\tf07-073-09.jpg\t m04-078-05.jpg   n06-128-06.jpg\n",
            "d05-021-04.jpg\tf07-076a-00.jpg  m04-078-06.jpg   n06-128-07.jpg\n",
            "d05-021-05.jpg\tf07-076a-01.jpg  m04-078-07.jpg   n06-128-08.jpg\n",
            "d05-021-06.jpg\tf07-076a-02.jpg  m04-081-00.jpg   n06-133-00.jpg\n",
            "d05-021-07.jpg\tf07-076a-03.jpg  m04-081-01.jpg   n06-133-01.jpg\n",
            "d05-021-08.jpg\tf07-076a-04.jpg  m04-081-02.jpg   n06-133-02.jpg\n",
            "d05-025-00.jpg\tf07-076a-05.jpg  m04-081-03.jpg   n06-133-03.jpg\n",
            "d05-025-01.jpg\tf07-076a-06.jpg  m04-081-04.jpg   n06-133-04.jpg\n",
            "d05-025-02.jpg\tf07-076a-07.jpg  m04-081-05.jpg   n06-133-05.jpg\n",
            "d05-025-03.jpg\tf07-076a-08.jpg  m04-081-06.jpg   n06-133-06.jpg\n",
            "d05-025-04.jpg\tf07-076a-09.jpg  m04-081-07.jpg   n06-133-07.jpg\n",
            "d05-025-05.jpg\tf07-076a-10.jpg  m04-081-08.jpg   n06-133-08.jpg\n",
            "d05-025-06.jpg\tf07-081a-00.jpg  m04-081-09.jpg   n06-140-00.jpg\n",
            "d05-025-07.jpg\tf07-081a-01.jpg  m04-081-10.jpg   n06-140-01.jpg\n",
            "d05-025-08.jpg\tf07-081a-02.jpg  m04-093-00.jpg   n06-140-02.jpg\n",
            "d05-025-09.jpg\tf07-081a-03.jpg  m04-093-01.jpg   n06-140-03.jpg\n",
            "d05-030-00.jpg\tf07-081a-04.jpg  m04-093-02.jpg   n06-140-04.jpg\n",
            "d05-030-01.jpg\tf07-081a-05.jpg  m04-093-03.jpg   n06-140-05.jpg\n",
            "d05-030-02.jpg\tf07-081a-06.jpg  m04-093-04.jpg   n06-140-06.jpg\n",
            "d05-030-03.jpg\tf07-081a-07.jpg  m04-093-05.jpg   n06-140-07.jpg\n",
            "d05-030-04.jpg\tf07-081a-08.jpg  m04-093-06.jpg   p01-147-00.jpg\n",
            "d05-030-05.jpg\tf07-081a-09.jpg  m04-093-07.jpg   p01-147-01.jpg\n",
            "d05-030-06.jpg\tf07-081a-10.jpg  m04-093-08.jpg   p01-147-02.jpg\n",
            "d05-030-07.jpg\tf07-081b-00.jpg  m04-093-09.jpg   p01-147-03.jpg\n",
            "d05-030-08.jpg\tf07-081b-01.jpg  m04-100-00.jpg   p01-147-04.jpg\n",
            "d05-040-00.jpg\tf07-081b-02.jpg  m04-100-01.jpg   p01-147-05.jpg\n",
            "d05-040-01.jpg\tf07-081b-03.jpg  m04-100-02.jpg   p01-147-06.jpg\n",
            "d05-040-02.jpg\tf07-081b-04.jpg  m04-100-03.jpg   p01-147-07.jpg\n",
            "d05-040-03.jpg\tf07-081b-05.jpg  m04-100-04.jpg   p01-147-08.jpg\n",
            "d05-040-04.jpg\tf07-081b-06.jpg  m04-100-05.jpg   p01-147-09.jpg\n",
            "d05-040-05.jpg\tf07-084a-00.jpg  m04-100-06.jpg   p01-147-10.jpg\n",
            "d06-003-00.jpg\tf07-084a-01.jpg  m04-100-07.jpg   p01-147-11.jpg\n",
            "d06-003-01.jpg\tf07-084a-02.jpg  m04-107-00.jpg   p01-155-00.jpg\n",
            "d06-003-02.jpg\tf07-084a-03.jpg  m04-107-01.jpg   p01-155-01.jpg\n",
            "d06-003-03.jpg\tf07-084a-04.jpg  m04-107-02.jpg   p01-155-02.jpg\n",
            "d06-003-04.jpg\tf07-084a-05.jpg  m04-107-03.jpg   p01-155-03.jpg\n",
            "d06-003-05.jpg\tf07-084a-06.jpg  m04-107-04.jpg   p01-155-04.jpg\n",
            "d06-003-06.jpg\tf07-084a-07.jpg  m04-107-05.jpg   p01-155-05.jpg\n",
            "d06-008-00.jpg\tf07-084a-08.jpg  m04-107-06.jpg   p01-155-06.jpg\n",
            "d06-008-01.jpg\tf07-084a-09.jpg  m04-107-07.jpg   p01-155-07.jpg\n",
            "d06-008-02.jpg\tf07-084a-10.jpg  m04-107-08.jpg   p01-155-08.jpg\n",
            "d06-008-03.jpg\tf07-084b-00.jpg  m04-107-09.jpg   p01-155-09.jpg\n",
            "d06-008-04.jpg\tf07-084b-01.jpg  m04-107-10.jpg   p01-168-00.jpg\n",
            "d06-008-05.jpg\tf07-084b-02.jpg  m04-113-00.jpg   p01-168-01.jpg\n",
            "d06-008-06.jpg\tf07-084b-03.jpg  m04-113-01.jpg   p01-168-02.jpg\n",
            "d06-008-07.jpg\tf07-084b-04.jpg  m04-113-02.jpg   p01-168-03.jpg\n",
            "d06-008-08.jpg\tf07-084b-05.jpg  m04-113-03.jpg   p01-168-04.jpg\n",
            "d06-008-09.jpg\tf07-084b-06.jpg  m04-113-04.jpg   p01-168-05.jpg\n",
            "d06-011-00.jpg\tf07-084b-07.jpg  m04-113-05.jpg   p01-168-06.jpg\n",
            "d06-011-01.jpg\tf07-084b-08.jpg  m04-113-06.jpg   p01-168-07.jpg\n",
            "d06-011-02.jpg\tf07-088a-00.jpg  m04-113-07.jpg   p01-174-00.jpg\n",
            "d06-011-03.jpg\tf07-088a-01.jpg  m04-113-08.jpg   p01-174-01.jpg\n",
            "d06-011-04.jpg\tf07-088a-02.jpg  m04-113-09.jpg   p01-174-02.jpg\n",
            "d06-011-05.jpg\tf07-088a-03.jpg  m04-113-10.jpg   p01-174-03.jpg\n",
            "d06-011-06.jpg\tf07-088a-04.jpg  m04-123-00.jpg   p01-174-04.jpg\n",
            "d06-011-07.jpg\tf07-088a-05.jpg  m04-123-01.jpg   p01-174-05.jpg\n",
            "d06-011-08.jpg\tf07-088a-06.jpg  m04-123-02.jpg   p01-174-06.jpg\n",
            "d06-011-09.jpg\tf07-088a-07.jpg  m04-123-03.jpg   p01-174-07.jpg\n",
            "d06-020-00.jpg\tf07-088a-08.jpg  m04-123-04.jpg   p01-174-08.jpg\n",
            "d06-020-01.jpg\tf07-088a-09.jpg  m04-123-05.jpg   p02-000-00.jpg\n",
            "d06-020-02.jpg\tf07-088b-00.jpg  m04-123-06.jpg   p02-000-01.jpg\n",
            "d06-020-03.jpg\tf07-088b-01.jpg  m04-123-07.jpg   p02-000-02.jpg\n",
            "d06-020-04.jpg\tf07-088b-02.jpg  m04-123-08.jpg   p02-000-03.jpg\n",
            "d06-020-05.jpg\tf07-088b-03.jpg  m04-123-09.jpg   p02-000-04.jpg\n",
            "d06-020-06.jpg\tf07-088b-04.jpg  m04-123-10.jpg   p02-000-05.jpg\n",
            "d06-020-07.jpg\tf07-088b-05.jpg  m04-131-00.jpg   p02-000-06.jpg\n",
            "d06-020-08.jpg\tf07-088b-06.jpg  m04-131-01.jpg   p02-008-00.jpg\n",
            "d06-020-09.jpg\tf07-092a-00.jpg  m04-131-02.jpg   p02-008-01.jpg\n",
            "d06-025-00.jpg\tf07-092a-01.jpg  m04-131-03.jpg   p02-008-02.jpg\n",
            "d06-025-01.jpg\tf07-092a-02.jpg  m04-131-04.jpg   p02-008-03.jpg\n",
            "d06-025-02.jpg\tf07-092a-03.jpg  m04-131-05.jpg   p02-008-04.jpg\n",
            "d06-025-03.jpg\tf07-092a-04.jpg  m04-131-06.jpg   p02-008-05.jpg\n",
            "d06-025-04.jpg\tf07-092a-05.jpg  m04-131-07.jpg   p02-008-06.jpg\n",
            "d06-025-05.jpg\tf07-092a-06.jpg  m04-131-08.jpg   p02-008-07.jpg\n",
            "d06-025-06.jpg\tf07-092a-07.jpg  m04-138-00.jpg   p02-008-08.jpg\n",
            "d06-025-07.jpg\tf07-092a-08.jpg  m04-138-01.jpg   p02-008-09.jpg\n",
            "d06-027-00.jpg\tf07-092b-00.jpg  m04-138-02.jpg   p02-008-10.jpg\n",
            "d06-027-01.jpg\tf07-092b-01.jpg  m04-138-03.jpg   p02-022-00.jpg\n",
            "d06-027-02.jpg\tf07-092b-02.jpg  m04-138-04.jpg   p02-022-01.jpg\n",
            "d06-027-03.jpg\tf07-092b-03.jpg  m04-138-05.jpg   p02-022-02.jpg\n",
            "d06-027-04.jpg\tf07-092b-04.jpg  m04-138-06.jpg   p02-022-03.jpg\n",
            "d06-027-05.jpg\tf07-092b-05.jpg  m04-138-07.jpg   p02-022-04.jpg\n",
            "d06-027-06.jpg\tf07-092b-06.jpg  m04-138-08.jpg   p02-022-05.jpg\n",
            "d06-027-07.jpg\tf07-096-00.jpg\t m04-138-09.jpg   p02-022-06.jpg\n",
            "d06-037-00.jpg\tf07-096-01.jpg\t m04-231-00.jpg   p02-022-07.jpg\n",
            "d06-037-01.jpg\tf07-096-02.jpg\t m04-231-01.jpg   p02-022-08.jpg\n",
            "d06-037-02.jpg\tf07-096-03.jpg\t m04-231-02.jpg   p02-027-00.jpg\n",
            "d06-037-03.jpg\tf07-096-04.jpg\t m04-231-03.jpg   p02-027-01.jpg\n",
            "d06-037-04.jpg\tf07-096-05.jpg\t m04-231-04.jpg   p02-027-02.jpg\n",
            "d06-037-05.jpg\tf07-096-06.jpg\t m04-231-05.jpg   p02-027-03.jpg\n",
            "d06-037-06.jpg\tf07-101b-00.jpg  m04-231-06.jpg   p02-027-04.jpg\n",
            "d06-037-07.jpg\tf07-101b-01.jpg  m04-238-00.jpg   p02-069-00.jpg\n",
            "d06-041-00.jpg\tf07-101b-02.jpg  m04-238-01.jpg   p02-069-01.jpg\n",
            "d06-041-01.jpg\tf07-101b-03.jpg  m04-238-02.jpg   p02-069-02.jpg\n",
            "d06-041-02.jpg\tf07-101b-04.jpg  m04-238-03.jpg   p02-069-03.jpg\n",
            "d06-041-03.jpg\tg01-004-00.jpg\t m04-238-04.jpg   p02-069-04.jpg\n",
            "d06-041-04.jpg\tg01-004-01.jpg\t m04-238-05.jpg   p02-069-05.jpg\n",
            "d06-041-05.jpg\tg01-004-02.jpg\t m04-246-00.jpg   p02-069-06.jpg\n",
            "d06-041-06.jpg\tg01-004-03.jpg\t m04-246-01.jpg   p02-069-07.jpg\n",
            "d06-041-07.jpg\tg01-004-04.jpg\t m04-246-02.jpg   p02-069-08.jpg\n",
            "d06-046-00.jpg\tg01-004-05.jpg\t m04-246-03.jpg   p02-069-09.jpg\n",
            "d06-046-01.jpg\tg01-008-00.jpg\t m04-246-04.jpg   p02-076-00.jpg\n",
            "d06-046-02.jpg\tg01-008-01.jpg\t m04-246-05.jpg   p02-076-01.jpg\n",
            "d06-046-03.jpg\tg01-008-02.jpg\t m04-246-06.jpg   p02-076-02.jpg\n",
            "d06-046-04.jpg\tg01-008-03.jpg\t m06-031-00.jpg   p02-076-03.jpg\n",
            "d06-046-05.jpg\tg01-008-04.jpg\t m06-031-01.jpg   p02-076-04.jpg\n",
            "d06-046-06.jpg\tg01-008-05.jpg\t m06-031-02.jpg   p02-076-05.jpg\n",
            "d06-046-07.jpg\tg01-008-06.jpg\t m06-031-03.jpg   p02-076-06.jpg\n",
            "d06-046-08.jpg\tg01-008-07.jpg\t m06-031-04.jpg   p02-076-07.jpg\n",
            "d06-046-09.jpg\tg01-008-08.jpg\t m06-031-05.jpg   p02-076-08.jpg\n",
            "d06-056-00.jpg\tg01-012-00.jpg\t m06-031-06.jpg   p02-076-09.jpg\n",
            "d06-056-01.jpg\tg01-012-01.jpg\t m06-042-00.jpg   p02-076-10.jpg\n",
            "d06-056-02.jpg\tg01-012-02.jpg\t m06-042-01.jpg   p02-081-00.jpg\n",
            "d06-056-03.jpg\tg01-012-03.jpg\t m06-042-02.jpg   p02-081-01.jpg\n",
            "d06-056-04.jpg\tg01-012-04.jpg\t m06-042-03.jpg   p02-081-02.jpg\n",
            "d06-056-05.jpg\tg01-012-05.jpg\t m06-042-04.jpg   p02-081-03.jpg\n",
            "d06-056-06.jpg\tg01-012-06.jpg\t m06-042-05.jpg   p02-081-04.jpg\n",
            "d06-056-07.jpg\tg01-016-00.jpg\t m06-048-00.jpg   p02-081-05.jpg\n",
            "d06-056-08.jpg\tg01-016-01.jpg\t m06-048-01.jpg   p02-081-06.jpg\n",
            "d06-060-00.jpg\tg01-016-02.jpg\t m06-048-02.jpg   p02-081-07.jpg\n",
            "d06-060-01.jpg\tg01-016-03.jpg\t m06-048-03.jpg   p02-081-08.jpg\n",
            "d06-060-02.jpg\tg01-016-04.jpg\t m06-048-04.jpg   p02-081-09.jpg\n",
            "d06-060-03.jpg\tg01-016-05.jpg\t m06-048-05.jpg   p02-090-00.jpg\n",
            "d06-060-04.jpg\tg01-016-06.jpg\t m06-048-06.jpg   p02-090-01.jpg\n",
            "d06-060-05.jpg\tg01-016-07.jpg\t m06-048-07.jpg   p02-090-02.jpg\n",
            "d06-060-06.jpg\tg01-019-00.jpg\t m06-056-00.jpg   p02-090-03.jpg\n",
            "d06-060-07.jpg\tg01-019-01.jpg\t m06-056-01.jpg   p02-090-04.jpg\n",
            "d06-060-08.jpg\tg01-019-02.jpg\t m06-056-02.jpg   p02-090-05.jpg\n",
            "d06-060-09.jpg\tg01-019-03.jpg\t m06-056-03.jpg   p02-090-06.jpg\n",
            "d06-063-00.jpg\tg01-019-04.jpg\t m06-056-04.jpg   p02-090-07.jpg\n",
            "d06-063-01.jpg\tg01-019-05.jpg\t m06-056-05.jpg   p02-090-08.jpg\n",
            "d06-063-02.jpg\tg01-019-06.jpg\t m06-067-00.jpg   p02-101-00.jpg\n",
            "d06-063-03.jpg\tg01-019-07.jpg\t m06-067-01.jpg   p02-101-01.jpg\n",
            "d06-063-04.jpg\tg01-019-08.jpg\t m06-067-02.jpg   p02-101-02.jpg\n",
            "d06-063-05.jpg\tg01-019-09.jpg\t m06-067-03.jpg   p02-101-03.jpg\n",
            "d06-063-06.jpg\tg01-025-00.jpg\t m06-067-04.jpg   p02-101-04.jpg\n",
            "d06-063-07.jpg\tg01-025-01.jpg\t m06-067-05.jpg   p02-101-05.jpg\n",
            "d06-063-08.jpg\tg01-025-02.jpg\t m06-067-06.jpg   p02-101-06.jpg\n",
            "d06-063-09.jpg\tg01-025-03.jpg\t m06-076-00.jpg   p02-101-07.jpg\n",
            "d06-063-10.jpg\tg01-025-04.jpg\t m06-076-01.jpg   p02-105-00.jpg\n",
            "d06-067-00.jpg\tg01-025-05.jpg\t m06-076-02.jpg   p02-105-01.jpg\n",
            "d06-067-01.jpg\tg01-025-06.jpg\t m06-076-03.jpg   p02-105-02.jpg\n",
            "d06-067-02.jpg\tg01-025-07.jpg\t m06-076-04.jpg   p02-105-03.jpg\n",
            "d06-067-03.jpg\tg01-025-08.jpg\t m06-076-05.jpg   p02-105-04.jpg\n",
            "d06-067-04.jpg\tg01-025-09.jpg\t m06-076-06.jpg   p02-105-05.jpg\n",
            "d06-067-05.jpg\tg01-027-00.jpg\t m06-083-00.jpg   p02-105-06.jpg\n",
            "d06-067-06.jpg\tg01-027-01.jpg\t m06-083-01.jpg   p02-105-07.jpg\n",
            "d06-067-07.jpg\tg01-027-02.jpg\t m06-083-02.jpg   p02-109-00.jpg\n",
            "d06-067-08.jpg\tg01-027-03.jpg\t m06-083-03.jpg   p02-109-01.jpg\n",
            "d06-067-09.jpg\tg01-027-04.jpg\t m06-083-04.jpg   p02-109-02.jpg\n",
            "d06-072-00.jpg\tg01-027-05.jpg\t m06-083-05.jpg   p02-109-03.jpg\n",
            "d06-072-01.jpg\tg01-027-06.jpg\t m06-083-06.jpg   p02-109-04.jpg\n",
            "d06-072-02.jpg\tg01-027-07.jpg\t m06-083-07.jpg   p02-109-05.jpg\n",
            "d06-072-03.jpg\tg01-027-08.jpg\t m06-091-00.jpg   p02-109-06.jpg\n",
            "d06-072-04.jpg\tg01-027-09.jpg\t m06-091-01.jpg   p02-109-07.jpg\n",
            "d06-072-05.jpg\tg01-031-00.jpg\t m06-091-02.jpg   p02-109-08.jpg\n",
            "d06-072-06.jpg\tg01-031-01.jpg\t m06-091-03.jpg   p02-115-00.jpg\n",
            "d06-072-07.jpg\tg01-031-02.jpg\t m06-091-04.jpg   p02-115-01.jpg\n",
            "d06-072-08.jpg\tg01-031-03.jpg\t m06-091-05.jpg   p02-115-02.jpg\n",
            "d06-072-09.jpg\tg01-031-04.jpg\t m06-091-06.jpg   p02-115-03.jpg\n",
            "d06-072-10.jpg\tg01-031-05.jpg\t m06-098-00.jpg   p02-115-04.jpg\n",
            "d06-076-00.jpg\tg01-031-06.jpg\t m06-098-01.jpg   p02-115-05.jpg\n",
            "d06-076-01.jpg\tg01-031-07.jpg\t m06-098-02.jpg   p02-115-06.jpg\n",
            "d06-076-02.jpg\tg01-031-08.jpg\t m06-098-03.jpg   p02-115-07.jpg\n",
            "d06-076-03.jpg\tg01-031-09.jpg\t m06-098-04.jpg   p02-115-08.jpg\n",
            "d06-076-04.jpg\tg01-031-10.jpg\t m06-098-05.jpg   p02-135-00.jpg\n",
            "d06-076-05.jpg\tg01-034-00.jpg\t m06-098-06.jpg   p02-135-01.jpg\n",
            "d06-086-00.jpg\tg01-034-01.jpg\t m06-106-00.jpg   p02-135-02.jpg\n",
            "d06-086-01.jpg\tg01-034-02.jpg\t m06-106-01.jpg   p02-135-03.jpg\n",
            "d06-086-02.jpg\tg01-034-03.jpg\t m06-106-02.jpg   p02-135-04.jpg\n",
            "d06-086-03.jpg\tg01-034-04.jpg\t m06-106-03.jpg   p02-135-05.jpg\n",
            "d06-086-04.jpg\tg01-034-05.jpg\t m06-106-04.jpg   p02-135-06.jpg\n",
            "d06-086-05.jpg\tg01-034-06.jpg\t m06-106-05.jpg   p02-135-07.jpg\n",
            "d06-086-06.jpg\tg01-034-07.jpg\t m06-106-06.jpg   p02-135-08.jpg\n",
            "d06-086-07.jpg\tg01-034-08.jpg\t m06-106-07.jpg   p02-139-00.jpg\n",
            "d06-086-08.jpg\tg01-037-00.jpg\t m06-106-08.jpg   p02-139-01.jpg\n",
            "d06-086-09.jpg\tg01-037-01.jpg\t m06-106-09.jpg   p02-139-02.jpg\n",
            "d06-086-10.jpg\tg01-037-02.jpg\t n01-000-00.jpg   p02-139-03.jpg\n",
            "d06-096-00.jpg\tg01-037-03.jpg\t n01-000-01.jpg   p02-139-04.jpg\n",
            "d06-096-01.jpg\tg01-037-04.jpg\t n01-000-02.jpg   p02-139-05.jpg\n",
            "d06-096-02.jpg\tg01-037-05.jpg\t n01-000-03.jpg   p02-144-00.jpg\n",
            "d06-096-03.jpg\tg01-037-06.jpg\t n01-000-04.jpg   p02-144-01.jpg\n",
            "d06-096-04.jpg\tg01-037-07.jpg\t n01-000-05.jpg   p02-144-02.jpg\n",
            "d06-096-05.jpg\tg01-037-08.jpg\t n01-000-06.jpg   p02-144-03.jpg\n",
            "d06-096-06.jpg\tg01-037-09.jpg\t n01-000-07.jpg   p02-144-04.jpg\n",
            "d06-096-07.jpg\tg01-039-00.jpg\t n01-004-00.jpg   p02-144-05.jpg\n",
            "d06-096-08.jpg\tg01-039-01.jpg\t n01-004-01.jpg   p02-144-06.jpg\n",
            "d06-100-00.jpg\tg01-039-02.jpg\t n01-004-02.jpg   p02-144-07.jpg\n",
            "d06-100-01.jpg\tg01-039-03.jpg\t n01-004-03.jpg   p02-144-08.jpg\n",
            "d06-100-02.jpg\tg01-039-04.jpg\t n01-004-04.jpg   p02-144-09.jpg\n",
            "d06-100-03.jpg\tg01-039-05.jpg\t n01-004-05.jpg   p02-144-10.jpg\n",
            "d06-100-04.jpg\tg01-039-06.jpg\t n01-004-06.jpg   p02-144-11.jpg\n",
            "d06-100-05.jpg\tg01-039-07.jpg\t n01-009-00.jpg   p02-150-00.jpg\n",
            "d06-100-06.jpg\tg01-039-08.jpg\t n01-009-01.jpg   p02-150-01.jpg\n",
            "d06-100-07.jpg\tg01-039-09.jpg\t n01-009-02.jpg   p02-150-02.jpg\n",
            "d06-104-00.jpg\tg01-043-00.jpg\t n01-009-03.jpg   p02-150-03.jpg\n",
            "d06-104-01.jpg\tg01-043-01.jpg\t n01-009-04.jpg   p02-150-04.jpg\n",
            "d06-104-02.jpg\tg01-043-02.jpg\t n01-009-05.jpg   p02-150-05.jpg\n",
            "d06-104-03.jpg\tg01-043-03.jpg\t n01-009-06.jpg   p02-150-06.jpg\n",
            "d06-104-04.jpg\tg01-043-04.jpg\t n01-009-07.jpg   p02-150-07.jpg\n",
            "d06-104-05.jpg\tg01-043-05.jpg\t n01-009-08.jpg   p02-150-08.jpg\n",
            "d06-104-06.jpg\tg01-043-06.jpg\t n01-020-00.jpg   p03-012-00.jpg\n",
            "d06-104-07.jpg\tg01-043-07.jpg\t n01-020-01.jpg   p03-012-01.jpg\n",
            "d06-104-08.jpg\tg01-043-08.jpg\t n01-020-02.jpg   p03-012-02.jpg\n",
            "d06-104-09.jpg\tg01-043-09.jpg\t n01-020-03.jpg   p03-012-03.jpg\n",
            "d06-104-10.jpg\tg01-045-00.jpg\t n01-020-04.jpg   p03-012-04.jpg\n",
            "d06-107-00.jpg\tg01-045-01.jpg\t n01-020-05.jpg   p03-012-05.jpg\n",
            "d06-107-01.jpg\tg01-045-02.jpg\t n01-020-06.jpg   p03-012-06.jpg\n",
            "d06-107-02.jpg\tg01-045-03.jpg\t n01-020-07.jpg   p03-012-07.jpg\n",
            "d06-107-03.jpg\tg01-045-04.jpg\t n01-020-08.jpg   p03-012-08.jpg\n",
            "d06-107-04.jpg\tg01-045-05.jpg\t n01-020-09.jpg   p03-012-09.jpg\n",
            "d06-107-05.jpg\tg01-045-06.jpg\t n01-031-00.jpg   p03-023-00.jpg\n",
            "d06-107-06.jpg\tg01-045-07.jpg\t n01-031-01.jpg   p03-023-01.jpg\n",
            "d06-107-07.jpg\tg01-045-08.jpg\t n01-031-02.jpg   p03-023-02.jpg\n",
            "d06-107-08.jpg\tg01-045-09.jpg\t n01-031-03.jpg   p03-023-03.jpg\n",
            "d06-107-09.jpg\tg01-067-00.jpg\t n01-031-04.jpg   p03-023-04.jpg\n",
            "d06-107-10.jpg\tg01-067-01.jpg\t n01-031-05.jpg   p03-023-05.jpg\n",
            "d06-111-00.jpg\tg01-067-02.jpg\t n01-031-06.jpg   p03-027-00.jpg\n",
            "d06-111-01.jpg\tg01-067-03.jpg\t n01-031-07.jpg   p03-027-01.jpg\n",
            "d06-111-02.jpg\tg01-067-04.jpg\t n01-031-08.jpg   p03-027-02.jpg\n",
            "d06-111-03.jpg\tg01-067-05.jpg\t n01-036-00.jpg   p03-027-03.jpg\n",
            "d06-111-04.jpg\tg01-067-06.jpg\t n01-036-01.jpg   p03-027-04.jpg\n",
            "d06-111-05.jpg\tg01-067-07.jpg\t n01-036-02.jpg   p03-027-05.jpg\n",
            "d06-111-06.jpg\tg01-067-08.jpg\t n01-036-03.jpg   p03-027-06.jpg\n",
            "d06-113-00.jpg\tg01-067-09.jpg\t n01-036-04.jpg   p03-027-07.jpg\n",
            "d06-113-01.jpg\tg01-070-00.jpg\t n01-036-05.jpg   p03-029-00.jpg\n",
            "d06-113-02.jpg\tg01-070-01.jpg\t n01-045-00.jpg   p03-029-01.jpg\n",
            "d06-113-03.jpg\tg01-070-02.jpg\t n01-045-01.jpg   p03-029-02.jpg\n",
            "d06-113-04.jpg\tg01-070-03.jpg\t n01-045-02.jpg   p03-029-03.jpg\n",
            "d07-082-00.jpg\tg01-070-04.jpg\t n01-045-03.jpg   p03-029-04.jpg\n",
            "d07-082-01.jpg\tg01-070-05.jpg\t n01-045-04.jpg   p03-029-05.jpg\n",
            "d07-082-02.jpg\tg01-070-06.jpg\t n01-045-05.jpg   p03-029-06.jpg\n",
            "d07-082-03.jpg\tg01-070-07.jpg\t n01-045-06.jpg   p03-029-07.jpg\n",
            "d07-082-04.jpg\tg01-070-08.jpg\t n01-045-07.jpg   p03-029-08.jpg\n",
            "d07-082-05.jpg\tg01-070-09.jpg\t n01-045-08.jpg   p03-029-09.jpg\n",
            "d07-082-06.jpg\tg01-074-00.jpg\t n01-045-09.jpg   p03-033-00.jpg\n",
            "d07-082-07.jpg\tg01-074-01.jpg\t n01-052-00.jpg   p03-033-01.jpg\n",
            "d07-082-08.jpg\tg01-074-02.jpg\t n01-052-01.jpg   p03-033-02.jpg\n",
            "d07-085-00.jpg\tg01-074-03.jpg\t n01-052-02.jpg   p03-033-03.jpg\n",
            "d07-085-01.jpg\tg01-074-04.jpg\t n01-052-03.jpg   p03-033-04.jpg\n",
            "d07-085-02.jpg\tg01-074-05.jpg\t n01-052-04.jpg   p03-033-05.jpg\n",
            "d07-085-03.jpg\tg01-074-06.jpg\t n01-052-05.jpg   p03-040-00.jpg\n",
            "d07-085-04.jpg\tg01-074-07.jpg\t n01-052-06.jpg   p03-040-01.jpg\n",
            "d07-085-05.jpg\tg01-074-08.jpg\t n01-052-07.jpg   p03-040-02.jpg\n",
            "d07-085-06.jpg\tg01-074-09.jpg\t n01-052-08.jpg   p03-040-03.jpg\n",
            "d07-085-07.jpg\tg01-088-00.jpg\t n01-052-09.jpg   p03-040-04.jpg\n",
            "d07-089-00.jpg\tg01-088-01.jpg\t n01-052-10.jpg   p03-040-05.jpg\n",
            "d07-089-01.jpg\tg01-088-02.jpg\t n01-052-11.jpg   p03-040-06.jpg\n",
            "d07-089-02.jpg\tg01-088-03.jpg\t n01-052-12.jpg   p03-040-07.jpg\n",
            "d07-089-03.jpg\tg01-088-04.jpg\t n01-057-00.jpg   p03-040-08.jpg\n",
            "d07-089-04.jpg\tg01-088-05.jpg\t n01-057-01.jpg   p03-047-00.jpg\n",
            "d07-089-05.jpg\tg01-088-06.jpg\t n01-057-02.jpg   p03-047-01.jpg\n",
            "d07-089-06.jpg\tg01-088-07.jpg\t n01-057-03.jpg   p03-047-02.jpg\n",
            "d07-089-07.jpg\tg01-088-08.jpg\t n01-057-04.jpg   p03-047-03.jpg\n",
            "d07-089-08.jpg\tg01-088-09.jpg\t n01-057-05.jpg   p03-047-04.jpg\n",
            "d07-089-09.jpg\tg02-059-00.jpg\t n01-057-06.jpg   p03-047-05.jpg\n",
            "d07-089-10.jpg\tg02-059-01.jpg\t n01-057-07.jpg   p03-047-06.jpg\n",
            "d07-093-00.jpg\tg02-059-02.jpg\t n01-057-08.jpg   p03-047-07.jpg\n",
            "d07-093-01.jpg\tg02-059-03.jpg\t n01-057-09.jpg   p03-047-08.jpg\n",
            "d07-093-02.jpg\tg02-059-04.jpg\t n02-004-00.jpg   p03-047-09.jpg\n",
            "d07-093-03.jpg\tg02-059-05.jpg\t n02-004-01.jpg   p03-072-00.jpg\n",
            "d07-093-04.jpg\tg02-059-06.jpg\t n02-004-02.jpg   p03-072-01.jpg\n",
            "d07-093-05.jpg\tg02-059-07.jpg\t n02-004-03.jpg   p03-072-02.jpg\n",
            "d07-093-06.jpg\tg02-062-00.jpg\t n02-004-04.jpg   p03-072-03.jpg\n",
            "d07-093-07.jpg\tg02-062-01.jpg\t n02-004-05.jpg   p03-072-04.jpg\n",
            "d07-093-08.jpg\tg02-062-02.jpg\t n02-004-06.jpg   p03-072-05.jpg\n",
            "d07-096-00.jpg\tg02-062-03.jpg\t n02-004-07.jpg   p03-072-06.jpg\n",
            "d07-096-01.jpg\tg02-062-04.jpg\t n02-004-08.jpg   p03-072-07.jpg\n",
            "d07-096-02.jpg\tg02-062-05.jpg\t n02-009-00.jpg   p03-080-00.jpg\n",
            "d07-096-03.jpg\tg02-062-06.jpg\t n02-009-01.jpg   p03-080-01.jpg\n",
            "d07-096-04.jpg\tg02-062-07.jpg\t n02-009-02.jpg   p03-080-02.jpg\n",
            "d07-096-05.jpg\tg02-062-08.jpg\t n02-009-03.jpg   p03-080-03.jpg\n",
            "d07-096-06.jpg\tg02-062-09.jpg\t n02-009-04.jpg   p03-080-04.jpg\n",
            "d07-096-07.jpg\tg02-065-00.jpg\t n02-009-05.jpg   p03-080-05.jpg\n",
            "d07-096-08.jpg\tg02-065-01.jpg\t n02-009-06.jpg   p03-080-06.jpg\n",
            "d07-096-09.jpg\tg02-065-02.jpg\t n02-028-00.jpg   p03-163-00.jpg\n",
            "d07-100-00.jpg\tg02-065-03.jpg\t n02-028-01.jpg   p03-163-01.jpg\n",
            "d07-100-01.jpg\tg02-065-04.jpg\t n02-028-02.jpg   p03-163-02.jpg\n",
            "d07-100-02.jpg\tg02-065-05.jpg\t n02-028-03.jpg   p03-163-03.jpg\n",
            "d07-100-03.jpg\tg02-065-06.jpg\t n02-028-04.jpg   p03-163-04.jpg\n",
            "d07-100-04.jpg\tg02-065-07.jpg\t n02-028-05.jpg   p03-163-05.jpg\n",
            "d07-100-05.jpg\tg02-065-08.jpg\t n02-028-06.jpg   p03-163-06.jpg\n",
            "d07-100-06.jpg\tg02-065-09.jpg\t n02-028-07.jpg   p03-163-07.jpg\n",
            "d07-100-07.jpg\tg02-073-00.jpg\t n02-028-08.jpg   p03-173-00.jpg\n",
            "d07-100-08.jpg\tg02-073-01.jpg\t n02-028-09.jpg   p03-173-01.jpg\n",
            "d07-100-09.jpg\tg02-073-02.jpg\t n02-033-00.jpg   p03-173-02.jpg\n",
            "d07-102-00.jpg\tg02-073-03.jpg\t n02-033-01.jpg   p03-173-03.jpg\n",
            "d07-102-01.jpg\tg02-073-04.jpg\t n02-033-02.jpg   p03-173-04.jpg\n",
            "d07-102-02.jpg\tg02-073-05.jpg\t n02-033-03.jpg   p03-173-05.jpg\n",
            "d07-102-03.jpg\tg03-000-00.jpg\t n02-033-04.jpg   p03-173-06.jpg\n",
            "d07-102-04.jpg\tg03-000-01.jpg\t n02-033-05.jpg   p03-173-07.jpg\n",
            "d07-102-05.jpg\tg03-000-02.jpg\t n02-033-06.jpg   p03-173-08.jpg\n",
            "d07-102-06.jpg\tg03-000-03.jpg\t n02-033-07.jpg   p03-181-00.jpg\n",
            "d07-102-07.jpg\tg03-000-04.jpg\t n02-033-08.jpg   p03-181-01.jpg\n",
            "e01-055-00.jpg\tg03-000-05.jpg\t n02-033-09.jpg   p03-181-02.jpg\n",
            "e01-055-01.jpg\tg03-000-06.jpg\t n02-037-00.jpg   p03-181-03.jpg\n",
            "e01-055-02.jpg\tg03-000-07.jpg\t n02-037-01.jpg   p03-181-04.jpg\n",
            "e01-055-03.jpg\tg03-000-08.jpg\t n02-037-02.jpg   p03-181-05.jpg\n",
            "e01-055-04.jpg\tg03-000-09.jpg\t n02-037-03.jpg   p03-181-06.jpg\n",
            "e01-055-05.jpg\tg03-004-00.jpg\t n02-037-04.jpg   p03-181-07.jpg\n",
            "e01-055-06.jpg\tg03-004-01.jpg\t n02-037-05.jpg   p03-181-08.jpg\n",
            "e01-055-07.jpg\tg03-004-02.jpg\t n02-037-06.jpg   p03-181-09.jpg\n",
            "e01-055-08.jpg\tg03-004-03.jpg\t n02-037-07.jpg   p03-189-00.jpg\n",
            "e01-055-09.jpg\tg03-004-04.jpg\t n02-037-08.jpg   p03-189-01.jpg\n",
            "e06-000-00.jpg\tg03-004-05.jpg\t n02-040-00.jpg   p03-189-02.jpg\n",
            "e06-000-01.jpg\tg03-032-00.jpg\t n02-040-01.jpg   p03-189-03.jpg\n",
            "e06-000-02.jpg\tg03-032-01.jpg\t n02-040-02.jpg   p03-189-04.jpg\n",
            "e06-000-03.jpg\tg03-032-02.jpg\t n02-040-03.jpg   p06-030-00.jpg\n",
            "e06-000-04.jpg\tg03-032-03.jpg\t n02-040-04.jpg   p06-030-01.jpg\n",
            "e06-000-05.jpg\tg03-032-04.jpg\t n02-040-05.jpg   p06-030-02.jpg\n",
            "e06-000-06.jpg\tg03-032-05.jpg\t n02-040-06.jpg   p06-030-03.jpg\n",
            "e06-000-07.jpg\tg03-032-06.jpg\t n02-040-07.jpg   p06-030-04.jpg\n",
            "e06-003-00.jpg\tg03-032-07.jpg\t n02-045-00.jpg   p06-030-05.jpg\n",
            "e06-003-01.jpg\tg03-040-00.jpg\t n02-045-01.jpg   p06-030-06.jpg\n",
            "e06-003-02.jpg\tg03-040-01.jpg\t n02-045-02.jpg   p06-030-07.jpg\n",
            "e06-003-03.jpg\tg03-040-02.jpg\t n02-045-03.jpg   p06-030-08.jpg\n",
            "e06-003-04.jpg\tg03-040-03.jpg\t n02-045-04.jpg   p06-042-00.jpg\n",
            "e06-003-05.jpg\tg03-040-04.jpg\t n02-045-05.jpg   p06-042-01.jpg\n",
            "e06-003-06.jpg\tg03-040-05.jpg\t n02-045-06.jpg   p06-042-02.jpg\n",
            "e06-003-07.jpg\tg03-040-06.jpg\t n02-045-07.jpg   p06-042-03.jpg\n",
            "e06-003-08.jpg\tg03-040-07.jpg\t n02-045-08.jpg   p06-042-04.jpg\n",
            "e06-003-09.jpg\tg03-043-00.jpg\t n02-049-00.jpg   p06-042-05.jpg\n",
            "e06-003-10.jpg\tg03-043-01.jpg\t n02-049-01.jpg   p06-042-06.jpg\n",
            "e06-010-00.jpg\tg03-043-02.jpg\t n02-049-02.jpg   p06-042-07.jpg\n",
            "e06-010-01.jpg\tg03-043-03.jpg\t n02-049-03.jpg   p06-042-08.jpg\n",
            "e06-010-02.jpg\tg03-043-04.jpg\t n02-049-04.jpg   p06-042-09.jpg\n",
            "e06-010-03.jpg\tg03-043-05.jpg\t n02-049-05.jpg   p06-042-10.jpg\n",
            "e06-010-04.jpg\tg03-043-06.jpg\t n02-054-00.jpg   p06-047-00.jpg\n",
            "e06-010-05.jpg\tg03-043-07.jpg\t n02-054-01.jpg   p06-047-01.jpg\n",
            "e06-010-06.jpg\tg03-043-08.jpg\t n02-054-02.jpg   p06-047-02.jpg\n",
            "e06-010-07.jpg\tg03-043-09.jpg\t n02-054-03.jpg   p06-047-03.jpg\n",
            "e06-015-00.jpg\tg03-043-10.jpg\t n02-054-04.jpg   p06-047-04.jpg\n",
            "e06-015-01.jpg\tg03-049-00.jpg\t n02-054-05.jpg   p06-047-05.jpg\n",
            "e06-015-02.jpg\tg03-049-01.jpg\t n02-054-06.jpg   p06-047-06.jpg\n",
            "e06-015-03.jpg\tg03-049-02.jpg\t n02-054-07.jpg   p06-047-07.jpg\n",
            "e06-015-04.jpg\tg03-049-03.jpg\t n02-054-08.jpg   p06-047-08.jpg\n",
            "e06-015-05.jpg\tg03-049-04.jpg\t n02-054-09.jpg   p06-047-09.jpg\n",
            "e06-015-06.jpg\tg03-049-05.jpg\t n02-062-00.jpg   p06-047-10.jpg\n",
            "e06-015-07.jpg\tg03-049-06.jpg\t n02-062-01.jpg   p06-052-00.jpg\n",
            "e06-015-08.jpg\tg03-049-07.jpg\t n02-062-02.jpg   p06-052-01.jpg\n",
            "e06-015-09.jpg\tg03-052-00.jpg\t n02-062-03.jpg   p06-052-02.jpg\n",
            "e06-021-00.jpg\tg03-052-01.jpg\t n02-062-04.jpg   p06-052-03.jpg\n",
            "e06-021-01.jpg\tg03-052-02.jpg\t n02-062-05.jpg   p06-052-04.jpg\n",
            "e06-021-02.jpg\tg03-052-03.jpg\t n02-062-06.jpg   p06-052-05.jpg\n",
            "e06-021-03.jpg\tg03-052-04.jpg\t n02-062-07.jpg   p06-052-06.jpg\n",
            "e06-021-04.jpg\tg03-052-05.jpg\t n02-104-00.jpg   p06-052-07.jpg\n",
            "e06-021-05.jpg\tg03-052-06.jpg\t n02-104-01.jpg   p06-052-08.jpg\n",
            "e06-021-06.jpg\tg03-052-07.jpg\t n02-104-02.jpg   p06-058-00.jpg\n",
            "e06-021-07.jpg\tg03-052-08.jpg\t n02-104-03.jpg   p06-058-01.jpg\n",
            "e06-021-08.jpg\tg03-052-09.jpg\t n02-104-04.jpg   p06-058-02.jpg\n",
            "e06-021-09.jpg\tg03-052-10.jpg\t n02-104-05.jpg   p06-058-03.jpg\n",
            "e06-021-10.jpg\tg03-064-00.jpg\t n02-104-06.jpg   p06-058-04.jpg\n",
            "e06-026-00.jpg\tg03-064-01.jpg\t n02-104-07.jpg   p06-058-05.jpg\n",
            "e06-026-01.jpg\tg03-064-02.jpg\t n02-109-00.jpg   p06-058-06.jpg\n",
            "e06-026-02.jpg\tg03-064-03.jpg\t n02-109-01.jpg   p06-058-07.jpg\n",
            "e06-026-03.jpg\tg03-064-04.jpg\t n02-109-02.jpg   p06-058-08.jpg\n",
            "e06-026-04.jpg\tg03-064-05.jpg\t n02-109-03.jpg   p06-058-09.jpg\n",
            "e06-026-05.jpg\tg03-064-06.jpg\t n02-109-04.jpg   p06-058-10.jpg\n",
            "e06-026-06.jpg\tg03-064-07.jpg\t n02-109-05.jpg   p06-069-00.jpg\n",
            "e06-026-07.jpg\tg04-022-00.jpg\t n02-109-06.jpg   p06-069-01.jpg\n",
            "e06-026-08.jpg\tg04-022-01.jpg\t n02-109-07.jpg   p06-069-02.jpg\n",
            "e06-026-09.jpg\tg04-022-02.jpg\t n02-114-00.jpg   p06-069-03.jpg\n",
            "e06-030-00.jpg\tg04-022-03.jpg\t n02-114-01.jpg   p06-069-04.jpg\n",
            "e06-030-01.jpg\tg04-022-04.jpg\t n02-114-02.jpg   p06-069-05.jpg\n",
            "e06-030-02.jpg\tg04-022-05.jpg\t n02-114-03.jpg   p06-069-06.jpg\n",
            "e06-030-03.jpg\tg04-022-06.jpg\t n02-114-04.jpg   p06-069-07.jpg\n",
            "e06-030-04.jpg\tg04-022-07.jpg\t n02-114-05.jpg   p06-069-08.jpg\n",
            "e06-030-05.jpg\tg04-043-00.jpg\t n02-114-06.jpg   p06-069-09.jpg\n",
            "e06-030-06.jpg\tg04-043-01.jpg\t n02-114-07.jpg   p06-069-10.jpg\n",
            "e06-030-07.jpg\tg04-043-02.jpg\t n02-114-08.jpg   p06-088-00.jpg\n",
            "e06-030-08.jpg\tg04-043-03.jpg\t n02-114-09.jpg   p06-088-01.jpg\n",
            "e06-030-09.jpg\tg04-043-04.jpg\t n02-120-00.jpg   p06-088-02.jpg\n",
            "e06-030-10.jpg\tg04-043-05.jpg\t n02-120-01.jpg   p06-088-03.jpg\n",
            "e06-033-00.jpg\tg04-043-06.jpg\t n02-120-02.jpg   p06-088-04.jpg\n",
            "e06-033-01.jpg\tg04-043-07.jpg\t n02-120-03.jpg   p06-088-05.jpg\n",
            "e06-033-02.jpg\tg04-043-08.jpg\t n02-120-04.jpg   p06-088-06.jpg\n",
            "e06-033-03.jpg\tg04-048-00.jpg\t n02-120-05.jpg   p06-088-07.jpg\n",
            "e06-033-04.jpg\tg04-048-01.jpg\t n02-120-06.jpg   p06-088-08.jpg\n",
            "e06-033-05.jpg\tg04-048-02.jpg\t n02-120-07.jpg   p06-088-09.jpg\n",
            "e06-033-06.jpg\tg04-048-03.jpg\t n02-127-00.jpg   p06-096-00.jpg\n",
            "e06-033-07.jpg\tg04-048-04.jpg\t n02-127-01.jpg   p06-096-01.jpg\n",
            "e06-033-08.jpg\tg04-048-05.jpg\t n02-127-02.jpg   p06-096-02.jpg\n",
            "e06-033-09.jpg\tg04-048-06.jpg\t n02-127-03.jpg   p06-096-03.jpg\n",
            "e06-046-00.jpg\tg04-048-07.jpg\t n02-127-04.jpg   p06-096-04.jpg\n",
            "e06-046-01.jpg\tg04-052-00.jpg\t n02-127-05.jpg   p06-096-05.jpg\n",
            "e06-046-02.jpg\tg04-052-01.jpg\t n02-127-06.jpg   p06-096-06.jpg\n",
            "e06-046-03.jpg\tg04-052-02.jpg\t n02-127-07.jpg   p06-096-07.jpg\n",
            "e06-046-04.jpg\tg04-052-03.jpg\t n02-151-00.jpg   p06-096-08.jpg\n",
            "e06-046-05.jpg\tg04-052-04.jpg\t n02-151-01.jpg   p06-096-09.jpg\n",
            "e06-049-00.jpg\tg04-052-05.jpg\t n02-151-02.jpg   p06-096-10.jpg\n",
            "e06-049-01.jpg\tg04-052-06.jpg\t n02-151-03.jpg   p06-104-00.jpg\n",
            "e06-049-02.jpg\tg04-068-00.jpg\t n02-151-04.jpg   p06-104-01.jpg\n",
            "e06-049-03.jpg\tg04-068-01.jpg\t n02-151-05.jpg   p06-104-02.jpg\n",
            "e06-049-04.jpg\tg04-068-02.jpg\t n02-151-06.jpg   p06-104-03.jpg\n",
            "e06-049-05.jpg\tg04-068-03.jpg\t n02-151-07.jpg   p06-104-04.jpg\n",
            "e06-049-06.jpg\tg04-068-04.jpg\t n02-151-08.jpg   p06-104-05.jpg\n",
            "e06-049-07.jpg\tg04-068-05.jpg\t n02-151-09.jpg   p06-104-06.jpg\n",
            "e06-049-08.jpg\tg04-068-06.jpg\t n02-151-10.jpg   p06-104-07.jpg\n",
            "e06-049-09.jpg\tg04-068-07.jpg\t n02-154-00.jpg   p06-104-08.jpg\n",
            "e06-053-00.jpg\tg04-068-08.jpg\t n02-154-01.jpg   p06-104-09.jpg\n",
            "e06-053-01.jpg\tg04-068-09.jpg\t n02-154-02.jpg   r03-053-00.jpg\n",
            "e06-053-02.jpg\tg04-072-00.jpg\t n02-154-03.jpg   r03-053-01.jpg\n",
            "e06-053-03.jpg\tg04-072-01.jpg\t n02-154-04.jpg   r03-053-02.jpg\n",
            "e06-053-04.jpg\tg04-072-02.jpg\t n02-154-05.jpg   r03-053-03.jpg\n",
            "e06-053-05.jpg\tg04-072-03.jpg\t n02-154-06.jpg   r03-053-04.jpg\n",
            "e06-053-06.jpg\tg04-072-04.jpg\t n02-157-00.jpg   r03-053-05.jpg\n",
            "e06-053-07.jpg\tg04-072-05.jpg\t n02-157-01.jpg   r03-053-06.jpg\n",
            "e06-053-08.jpg\tg04-072-06.jpg\t n02-157-02.jpg   r03-053-07.jpg\n",
            "e06-070-00.jpg\tg04-072-07.jpg\t n02-157-03.jpg   r03-053-08.jpg\n",
            "e06-070-01.jpg\tg04-072-08.jpg\t n02-157-04.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Assuming 'path' is defined and points to the base directory of the dataset\n",
        "# The images are located in the 'image' subdirectory relative to 'path'\n",
        "image_directory = path / \"image\"\n",
        "\n",
        "# Use glob to find all .jpg files in the image directory\n",
        "image_paths = sorted(glob.glob(str(image_directory / \"*.jpg\")))\n",
        "\n",
        "print(f\"Found {len(image_paths)} images in the dataset.\")\n",
        "print(\"First 5 image paths:\")\n",
        "for i, img_path in enumerate(image_paths[:5]):\n",
        "    print(f\"  {i+1}: {img_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_mnxogDU-oE",
        "outputId": "c22eb31a-fc7c-4c3f-ed37-d7d85090a2b1"
      },
      "id": "7_mnxogDU-oE",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2915 images in the dataset.\n",
            "First 5 image paths:\n",
            "  1: /kaggle/input/iam-trocr/IAM/image/c04-110-00.jpg\n",
            "  2: /kaggle/input/iam-trocr/IAM/image/c04-110-01.jpg\n",
            "  3: /kaggle/input/iam-trocr/IAM/image/c04-110-02.jpg\n",
            "  4: /kaggle/input/iam-trocr/IAM/image/c04-110-03.jpg\n",
            "  5: /kaggle/input/iam-trocr/IAM/image/c04-116-00.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class IAMImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB') # Load as RGB (or 'L' for grayscale if preferred)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # For now, we'll just return the image.\n",
        "        # In a real scenario, you'd also load and return the corresponding label/text.\n",
        "        return image\n",
        "\n",
        "# Define transformations (you can customize these)\n",
        "# Example: Resize to 224x224 and convert to tensor, then normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet normalization\n",
        "])\n",
        "\n",
        "# Instantiate your custom dataset\n",
        "# 'image_paths' is assumed to be defined from a previous cell\n",
        "iam_dataset = IAMImageDataset(image_paths=image_paths, transform=transform)\n",
        "\n",
        "print(f\"Number of samples in the dataset: {len(iam_dataset)}\")\n",
        "\n",
        "# To get a single image from the dataset:\n",
        "single_image_tensor = iam_dataset[0]\n",
        "print(f\"Shape of a single image tensor: {single_image_tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoYTHiYlT19E",
        "outputId": "944ba3a4-9f5e-47d2-bcfe-5667b9408e04"
      },
      "id": "DoYTHiYlT19E",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in the dataset: 2915\n",
            "Shape of a single image tensor: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3f091663",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "be1e78b280bb4c5d91bc2040350361ef",
            "e1b19c14ebc74feea26288dfcc117ec5",
            "85751e4907604f6db799f9ee7e11afa7",
            "52a5ae3948fc491f83286a05f022ffc9",
            "c37551fd7aff463fbf9b2b48abb21bfd",
            "705d4cba4d2e4b698e0209d8137097a4",
            "67146d10267b463fb7484d5796f30003",
            "1042849791514870b1ac6b76caae53bb",
            "b91512bd1cdb492abbbcd971b3326008",
            "3fad7dd7b34f4375b57f4f50c6924615",
            "1f80c52ac75043dbb9e0057cc61ba5cc",
            "c4530b21db824df78a2ef785bd318645",
            "c0783babc6f941d5aebecc79071bdaba",
            "f073e5a72fe0473caac7794a7cf9042b",
            "1ffadd1e30c24836a7fecd5d1842d9fe",
            "65b0e91d224d4607ba35250be0466184",
            "ccd296def8df4cdfbe9f169f8e37c443",
            "20e99a984bfc4c73b9a3967ea3892709",
            "02ea981317c14935918a46a35a17792f",
            "3db302b414404c10924bd6b436cea2d2",
            "ea0c57ecb6014647a87611040c8149c5",
            "ced2813dabd04495bfd564c30411afff",
            "1d299a3c913d4192a681be29c8c8a948",
            "121e4aab9c31462b882841e20415c656",
            "c83749e386c04a0596584d30022ef735",
            "43517fa146d14e85bfea93d12b489261",
            "8eda683780d74b83929c9061da6274dc",
            "22c19a01d7404a0aa23696a439bbfe28",
            "20964626779643a5a2c7af80a6f7555d",
            "762bbf3b1eeb4c1b9edc03f0f986ce5c",
            "4406c79e5b104dbeaa98357c39b384b9",
            "9cbe538b51d44f239ce9637dc48abdb7",
            "365cf321ca9048e98157a6179bc107b5",
            "34d9473c0d7945f591549c8babbd15fa",
            "c74ab8bdad6b4ff3ac28cdc0807b42dd",
            "c744e04333564357b000e70e576e0f5b",
            "58355717cb5c473abc1f026ce3e9d8e4",
            "74007dad360c4051a48e3a66ad64f1e0",
            "e820ec00e205492ea448f86aa0385201",
            "87bbc330f10d4a8b90d9655e081e404d",
            "56ec3f2522ae486cb85985cd52476950",
            "28f32d2084cb4a2fb6b9c09d52c663ab",
            "4a034704b78d433aa8f2cdd0e30c094b",
            "4a0022da3a6542f8adea36225476cbe4"
          ]
        },
        "id": "3f091663",
        "outputId": "6a696290-8e96-41ce-82c8-acbbb9ea7796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be1e78b280bb4c5d91bc2040350361ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4530b21db824df78a2ef785bd318645"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/478 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d299a3c913d4192a681be29c8c8a948"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VisionEncoderDecoderModel LOAD REPORT from: microsoft/trocr-base-handwritten\n",
            "Key                         | Status  | \n",
            "----------------------------+---------+-\n",
            "encoder.pooler.dense.weight | MISSING | \n",
            "encoder.pooler.dense.bias   | MISSING | \n",
            "\n",
            "Notes:\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34d9473c0d7945f591549c8babbd15fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionEncoderDecoderModel(\n",
              "  (encoder): ViTModel(\n",
              "    (embeddings): ViTEmbeddings(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ViTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ViTLayer(\n",
              "          (attention): ViTAttention(\n",
              "            (attention): ViTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (output): ViTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ViTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ViTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (pooler): ViTPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (decoder): TrOCRForCausalLM(\n",
              "    (model): TrOCRDecoderWrapper(\n",
              "      (decoder): TrOCRDecoder(\n",
              "        (embed_tokens): TrOCRScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
              "        (embed_positions): TrOCRLearnedPositionalEmbedding(514, 1024)\n",
              "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (layers): ModuleList(\n",
              "          (0-11): 12 x TrOCRDecoderLayer(\n",
              "            (self_attn): TrOCRAttention(\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (activation_fn): GELUActivation()\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (encoder_attn): TrOCRAttention(\n",
              "              (k_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (output_projection): Linear(in_features=1024, out_features=50265, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from transformers import VisionEncoderDecoderModel, TrOCRProcessor\n",
        "import torch\n",
        "\n",
        "# Load the model\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8235135b",
      "metadata": {
        "id": "8235135b"
      },
      "source": [
        "1. Quantas camadas tem o modelo TrOCR?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "20363987",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20363987",
        "outputId": "3d76b7f2-cb5a-4929-f72d-09f7cfe9bae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bloco 0 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 1 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 2 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 3 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 4 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 5 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 6 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 7 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 8 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 9 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 10 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 11 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "Bloco 0 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "Bloco 1 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "Bloco 2 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "Bloco 3 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "Bloco 4 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "Bloco 5 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "Bloco 6 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "Bloco 7 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "Bloco 8 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "Bloco 9 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "Bloco 10 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "Bloco 11 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n"
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(model.encoder.encoder.layer):\n",
        "    print(f\"Bloco {i} ->\", type(layer))\n",
        "for i, layer in enumerate(model.decoder.model.decoder.layers):\n",
        "    print(f\"Bloco {i} ->\", type(layer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b40e2f9",
      "metadata": {
        "id": "2b40e2f9"
      },
      "source": [
        "2. Quais os mdulos de todas as camadas do TrOCR?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ef4b451f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef4b451f",
        "outputId": "73577c6f-a896-4264-efa9-d7b467f62b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> <class 'transformers.models.vit.modeling_vit.ViTModel'>\n",
            "embeddings -> <class 'transformers.models.vit.modeling_vit.ViTEmbeddings'>\n",
            "embeddings.patch_embeddings -> <class 'transformers.models.vit.modeling_vit.ViTPatchEmbeddings'>\n",
            "embeddings.patch_embeddings.projection -> <class 'torch.nn.modules.conv.Conv2d'>\n",
            "embeddings.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder -> <class 'transformers.models.vit.modeling_vit.ViTEncoder'>\n",
            "encoder.layer -> <class 'torch.nn.modules.container.ModuleList'>\n",
            "encoder.layer.0 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.0.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.0.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.0.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.0.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.0.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.0.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.0.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.0.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.0.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.0.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.0.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.0.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.0.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.0.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.0.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.0.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.1 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.1.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.1.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.1.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.1.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.1.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.1.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.1.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.1.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.1.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.1.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.1.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.1.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.1.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.1.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.1.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.1.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.2 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.2.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.2.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.2.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.2.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.2.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.2.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.2.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.2.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.2.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.2.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.2.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.2.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.2.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.2.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.2.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.2.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.3 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.3.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.3.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.3.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.3.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.3.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.3.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.3.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.3.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.3.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.3.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.3.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.3.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.3.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.3.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.3.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.3.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.4 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.4.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.4.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.4.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.4.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.4.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.4.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.4.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.4.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.4.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.4.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.4.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.4.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.4.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.4.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.4.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.4.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.5 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.5.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.5.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.5.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.5.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.5.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.5.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.5.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.5.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.5.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.5.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.5.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.5.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.5.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.5.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.5.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.5.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.6 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.6.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.6.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.6.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.6.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.6.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.6.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.6.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.6.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.6.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.6.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.6.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.6.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.6.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.6.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.6.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.6.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.7 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.7.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.7.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.7.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.7.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.7.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.7.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.7.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.7.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.7.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.7.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.7.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.7.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.7.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.7.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.7.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.7.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.8 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.8.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.8.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.8.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.8.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.8.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.8.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.8.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.8.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.8.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.8.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.8.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.8.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.8.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.8.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.8.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.8.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.9 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.9.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.9.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.9.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.9.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.9.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.9.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.9.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.9.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.9.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.9.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.9.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.9.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.9.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.9.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.9.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.9.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.10 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.10.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.10.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.10.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.10.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.10.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.10.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.10.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.10.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.10.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.10.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.10.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.10.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.10.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.10.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.10.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.10.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.11 -> <class 'transformers.models.vit.modeling_vit.ViTLayer'>\n",
            "encoder.layer.11.attention -> <class 'transformers.models.vit.modeling_vit.ViTAttention'>\n",
            "encoder.layer.11.attention.attention -> <class 'transformers.models.vit.modeling_vit.ViTSelfAttention'>\n",
            "encoder.layer.11.attention.attention.query -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.11.attention.attention.key -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.11.attention.attention.value -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.11.attention.output -> <class 'transformers.models.vit.modeling_vit.ViTSelfOutput'>\n",
            "encoder.layer.11.attention.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.11.attention.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.11.intermediate -> <class 'transformers.models.vit.modeling_vit.ViTIntermediate'>\n",
            "encoder.layer.11.intermediate.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.11.intermediate.intermediate_act_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "encoder.layer.11.output -> <class 'transformers.models.vit.modeling_vit.ViTOutput'>\n",
            "encoder.layer.11.output.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "encoder.layer.11.output.dropout -> <class 'torch.nn.modules.dropout.Dropout'>\n",
            "encoder.layer.11.layernorm_before -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "encoder.layer.11.layernorm_after -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "layernorm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "pooler -> <class 'transformers.models.vit.modeling_vit.ViTPooler'>\n",
            "pooler.dense -> <class 'torch.nn.modules.linear.Linear'>\n",
            "pooler.activation -> <class 'torch.nn.modules.activation.Tanh'>\n"
          ]
        }
      ],
      "source": [
        "for name, module in model.encoder.named_modules():\n",
        "    print(name, \"->\", type(module))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f749b199",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f749b199",
        "outputId": "33e9ac0e-eac2-4d9f-d085-61047826270a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'>\n",
            "model -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderWrapper'>\n",
            "model.decoder -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoder'>\n",
            "model.decoder.embed_tokens -> <class 'transformers.models.trocr.modeling_trocr.TrOCRScaledWordEmbedding'>\n",
            "model.decoder.embed_positions -> <class 'transformers.models.trocr.modeling_trocr.TrOCRLearnedPositionalEmbedding'>\n",
            "model.decoder.layernorm_embedding -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers -> <class 'torch.nn.modules.container.ModuleList'>\n",
            "model.decoder.layers.0 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.0.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.0.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.0.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.0.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.0.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.0.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.0.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.0.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.0.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.0.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.0.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.0.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.0.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.0.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.0.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.0.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.1 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.1.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.1.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.1.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.1.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.1.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.1.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.1.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.1.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.1.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.1.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.1.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.1.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.1.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.1.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.1.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.1.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.2 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.2.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.2.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.2.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.2.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.2.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.2.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.2.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.2.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.2.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.2.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.2.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.2.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.2.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.2.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.2.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.2.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.3 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.3.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.3.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.3.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.3.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.3.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.3.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.3.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.3.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.3.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.3.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.3.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.3.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.3.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.3.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.3.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.3.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.4 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.4.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.4.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.4.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.4.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.4.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.4.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.4.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.4.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.4.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.4.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.4.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.4.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.4.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.4.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.4.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.4.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.5 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.5.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.5.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.5.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.5.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.5.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.5.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.5.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.5.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.5.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.5.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.5.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.5.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.5.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.5.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.5.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.5.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.6 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.6.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.6.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.6.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.6.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.6.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.6.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.6.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.6.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.6.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.6.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.6.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.6.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.6.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.6.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.6.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.6.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.7 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.7.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.7.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.7.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.7.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.7.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.7.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.7.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.7.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.7.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.7.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.7.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.7.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.7.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.7.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.7.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.7.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.8 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.8.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.8.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.8.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.8.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.8.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.8.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.8.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.8.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.8.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.8.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.8.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.8.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.8.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.8.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.8.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.8.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.9 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.9.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.9.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.9.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.9.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.9.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.9.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.9.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.9.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.9.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.9.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.9.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.9.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.9.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.9.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.9.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.9.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.10 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.10.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.10.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.10.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.10.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.10.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.10.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.10.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.10.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.10.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.10.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.10.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.10.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.10.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.10.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.10.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.10.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.11 -> <class 'transformers.models.trocr.modeling_trocr.TrOCRDecoderLayer'>\n",
            "model.decoder.layers.11.self_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.11.self_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.11.self_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.11.self_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.11.self_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.11.activation_fn -> <class 'transformers.activations.GELUActivation'>\n",
            "model.decoder.layers.11.self_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.11.encoder_attn -> <class 'transformers.models.trocr.modeling_trocr.TrOCRAttention'>\n",
            "model.decoder.layers.11.encoder_attn.k_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.11.encoder_attn.v_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.11.encoder_attn.q_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.11.encoder_attn.out_proj -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.11.encoder_attn_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "model.decoder.layers.11.fc1 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.11.fc2 -> <class 'torch.nn.modules.linear.Linear'>\n",
            "model.decoder.layers.11.final_layer_norm -> <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "output_projection -> <class 'torch.nn.modules.linear.Linear'>\n"
          ]
        }
      ],
      "source": [
        "for name, module in model.decoder.named_modules():\n",
        "    print(name, \"->\", type(module))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2337dca5",
      "metadata": {
        "id": "2337dca5"
      },
      "source": [
        "As principais camadas do encoder(ViT) so as camadas de Embedding, Self-Attention, Feed-Forward, Layer Norm e Residual Connection\n",
        "As principais camadas do decoder(Texto) so as camadas de Embedding, Self-Attention, Cross-Attention, Feed-Forward e Layer Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8d0e969",
      "metadata": {
        "id": "e8d0e969"
      },
      "source": [
        "3. Quantos paramtros tem o TrORC?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cacd54a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cacd54a4",
        "outputId": "4a947f97-012c-404f-958d-28707fc6f4dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parmetros do Encoder: 86653440\n",
            "Parmetros do Decoder: 247268352\n",
            "Parmetros Totais: 333921792\n"
          ]
        }
      ],
      "source": [
        "encoder_params = sum(p.numel() for p in model.encoder.parameters())\n",
        "print(\"Parmetros do Encoder:\", encoder_params)\n",
        "\n",
        "decoder_params = sum(p.numel() for p in model.decoder.parameters())\n",
        "print(\"Parmetros do Decoder:\", decoder_params)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"Parmetros Totais:\", total_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfccba40",
      "metadata": {
        "id": "bfccba40"
      },
      "source": [
        "4. Quais os paramtros de cada camada?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7e902648",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e902648",
        "outputId": "9e0564ee-ff11-46dd-d858-c6f6c991e565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings.cls_token torch.Size([1, 1, 768])\n",
            "embeddings.position_embeddings torch.Size([1, 577, 768])\n",
            "embeddings.patch_embeddings.projection.weight torch.Size([768, 3, 16, 16])\n",
            "embeddings.patch_embeddings.projection.bias torch.Size([768])\n",
            "encoder.layer.0.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.0.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.0.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "encoder.layer.0.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.0.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.0.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.0.layernorm_after.bias torch.Size([768])\n",
            "encoder.layer.1.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.1.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.1.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "encoder.layer.1.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.1.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.1.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.1.layernorm_after.bias torch.Size([768])\n",
            "encoder.layer.2.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.2.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.2.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "encoder.layer.2.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.2.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.2.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.2.layernorm_after.bias torch.Size([768])\n",
            "encoder.layer.3.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.3.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.3.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "encoder.layer.3.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.3.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.3.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.3.layernorm_after.bias torch.Size([768])\n",
            "encoder.layer.4.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.4.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.4.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "encoder.layer.4.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.4.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.4.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.4.layernorm_after.bias torch.Size([768])\n",
            "encoder.layer.5.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.5.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.5.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "encoder.layer.5.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.5.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.5.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.5.layernorm_after.bias torch.Size([768])\n",
            "encoder.layer.6.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.6.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.6.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "encoder.layer.6.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.6.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.6.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.6.layernorm_after.bias torch.Size([768])\n",
            "encoder.layer.7.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.7.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.7.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "encoder.layer.7.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.7.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.7.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.7.layernorm_after.bias torch.Size([768])\n",
            "encoder.layer.8.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.8.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.8.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "encoder.layer.8.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.8.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.8.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.8.layernorm_after.bias torch.Size([768])\n",
            "encoder.layer.9.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.9.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.9.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "encoder.layer.9.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.9.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.9.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.9.layernorm_after.bias torch.Size([768])\n",
            "encoder.layer.10.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.10.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.10.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "encoder.layer.10.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.10.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.10.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.10.layernorm_after.bias torch.Size([768])\n",
            "encoder.layer.11.attention.attention.query.weight torch.Size([768, 768])\n",
            "encoder.layer.11.attention.attention.key.weight torch.Size([768, 768])\n",
            "encoder.layer.11.attention.attention.value.weight torch.Size([768, 768])\n",
            "encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "encoder.layer.11.layernorm_before.weight torch.Size([768])\n",
            "encoder.layer.11.layernorm_before.bias torch.Size([768])\n",
            "encoder.layer.11.layernorm_after.weight torch.Size([768])\n",
            "encoder.layer.11.layernorm_after.bias torch.Size([768])\n",
            "layernorm.weight torch.Size([768])\n",
            "layernorm.bias torch.Size([768])\n",
            "pooler.dense.weight torch.Size([768, 768])\n",
            "pooler.dense.bias torch.Size([768])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.encoder.named_parameters():\n",
        "    print(name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4b90a21f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b90a21f",
        "outputId": "3531b0f6-3a5f-4538-81e4-00df1f6848b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.decoder.embed_tokens.weight torch.Size([50265, 1024])\n",
            "model.decoder.embed_positions.weight torch.Size([514, 1024])\n",
            "model.decoder.layernorm_embedding.weight torch.Size([1024])\n",
            "model.decoder.layernorm_embedding.bias torch.Size([1024])\n",
            "model.decoder.layers.0.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.0.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.0.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.0.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.0.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.0.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.0.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.0.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.0.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.0.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.0.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.0.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.0.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.0.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.0.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.0.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.0.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.0.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.0.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.0.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.0.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.0.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.0.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.0.final_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.1.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.1.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.1.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.1.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.1.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.1.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.1.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.1.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.1.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.1.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.1.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.1.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.1.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.1.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.1.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.1.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.1.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.1.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.1.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.1.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.1.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.1.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.1.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.1.final_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.2.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.2.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.2.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.2.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.2.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.2.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.2.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.2.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.2.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.2.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.2.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.2.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.2.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.2.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.2.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.2.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.2.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.2.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.2.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.2.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.2.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.2.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.2.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.2.final_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.3.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.3.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.3.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.3.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.3.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.3.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.3.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.3.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.3.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.3.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.3.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.3.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.3.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.3.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.3.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.3.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.3.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.3.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.3.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.3.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.3.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.3.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.3.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.3.final_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.4.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.4.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.4.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.4.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.4.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.4.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.4.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.4.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.4.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.4.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.4.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.4.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.4.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.4.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.4.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.4.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.4.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.4.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.4.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.4.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.4.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.4.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.4.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.4.final_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.5.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.5.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.5.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.5.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.5.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.5.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.5.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.5.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.5.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.5.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.5.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.5.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.5.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.5.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.5.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.5.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.5.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.5.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.5.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.5.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.5.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.5.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.5.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.5.final_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.6.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.6.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.6.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.6.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.6.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.6.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.6.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.6.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.6.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.6.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.6.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.6.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.6.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.6.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.6.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.6.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.6.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.6.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.6.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.6.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.6.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.6.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.6.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.6.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.6.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.6.final_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.7.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.7.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.7.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.7.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.7.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.7.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.7.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.7.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.7.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.7.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.7.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.7.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.7.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.7.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.7.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.7.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.7.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.7.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.7.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.7.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.7.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.7.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.7.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.7.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.7.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.7.final_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.8.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.8.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.8.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.8.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.8.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.8.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.8.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.8.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.8.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.8.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.8.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.8.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.8.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.8.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.8.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.8.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.8.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.8.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.8.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.8.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.8.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.8.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.8.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.8.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.8.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.8.final_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.9.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.9.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.9.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.9.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.9.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.9.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.9.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.9.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.9.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.9.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.9.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.9.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.9.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.9.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.9.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.9.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.9.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.9.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.9.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.9.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.9.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.9.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.9.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.9.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.9.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.9.final_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.10.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.10.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.10.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.10.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.10.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.10.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.10.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.10.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.10.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.10.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.10.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.10.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.10.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.10.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.10.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.10.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.10.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.10.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.10.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.10.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.10.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.10.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.10.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.10.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.10.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.10.final_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.11.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.11.self_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.11.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.11.self_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.11.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.11.self_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.11.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.11.self_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.11.self_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.11.self_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.11.encoder_attn.k_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.11.encoder_attn.k_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.11.encoder_attn.v_proj.weight torch.Size([1024, 768])\n",
            "model.decoder.layers.11.encoder_attn.v_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.11.encoder_attn.q_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.11.encoder_attn.q_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.11.encoder_attn.out_proj.weight torch.Size([1024, 1024])\n",
            "model.decoder.layers.11.encoder_attn.out_proj.bias torch.Size([1024])\n",
            "model.decoder.layers.11.encoder_attn_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.11.encoder_attn_layer_norm.bias torch.Size([1024])\n",
            "model.decoder.layers.11.fc1.weight torch.Size([4096, 1024])\n",
            "model.decoder.layers.11.fc1.bias torch.Size([4096])\n",
            "model.decoder.layers.11.fc2.weight torch.Size([1024, 4096])\n",
            "model.decoder.layers.11.fc2.bias torch.Size([1024])\n",
            "model.decoder.layers.11.final_layer_norm.weight torch.Size([1024])\n",
            "model.decoder.layers.11.final_layer_norm.bias torch.Size([1024])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.decoder.named_parameters():\n",
        "    print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9afa76fa",
      "metadata": {
        "id": "9afa76fa"
      },
      "source": [
        "RESUMO GERAL:\n",
        "\n",
        "Self-Attention  um mecanismo que permite que cada token preste ateno nos outros tokens da mesma sequncia para entender melhor o contexto.\n",
        "\n",
        "q(Query) = \"O que eu quero buscar?\"\n",
        "k(Key) = \"O que eu ofereo?\"\n",
        "v(Value) = \"O que eu passo adiante?\"\n",
        "\n",
        "Cross-Attention  o mecanismo que permite que o decoder olhe para a sada do encoder e use essa informao para gerar o prximo token corretamente.\n",
        "\n",
        "O Feed-Forward processa cada token de forma independente, transformando o vetor de ateno em algo mais rico e no-linear.\n",
        "\n",
        "LayerNorm mantm os vetores dos tokens estveis e equilibrados em todas as subcamadas do Transformer.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be1e78b280bb4c5d91bc2040350361ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1b19c14ebc74feea26288dfcc117ec5",
              "IPY_MODEL_85751e4907604f6db799f9ee7e11afa7",
              "IPY_MODEL_52a5ae3948fc491f83286a05f022ffc9"
            ],
            "layout": "IPY_MODEL_c37551fd7aff463fbf9b2b48abb21bfd"
          }
        },
        "e1b19c14ebc74feea26288dfcc117ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_705d4cba4d2e4b698e0209d8137097a4",
            "placeholder": "",
            "style": "IPY_MODEL_67146d10267b463fb7484d5796f30003",
            "value": "config.json:"
          }
        },
        "85751e4907604f6db799f9ee7e11afa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1042849791514870b1ac6b76caae53bb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b91512bd1cdb492abbbcd971b3326008",
            "value": 1
          }
        },
        "52a5ae3948fc491f83286a05f022ffc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fad7dd7b34f4375b57f4f50c6924615",
            "placeholder": "",
            "style": "IPY_MODEL_1f80c52ac75043dbb9e0057cc61ba5cc",
            "value": "4.17k/?[00:00&lt;00:00,234kB/s]"
          }
        },
        "c37551fd7aff463fbf9b2b48abb21bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "705d4cba4d2e4b698e0209d8137097a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67146d10267b463fb7484d5796f30003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1042849791514870b1ac6b76caae53bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b91512bd1cdb492abbbcd971b3326008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fad7dd7b34f4375b57f4f50c6924615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f80c52ac75043dbb9e0057cc61ba5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4530b21db824df78a2ef785bd318645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0783babc6f941d5aebecc79071bdaba",
              "IPY_MODEL_f073e5a72fe0473caac7794a7cf9042b",
              "IPY_MODEL_1ffadd1e30c24836a7fecd5d1842d9fe"
            ],
            "layout": "IPY_MODEL_65b0e91d224d4607ba35250be0466184"
          }
        },
        "c0783babc6f941d5aebecc79071bdaba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccd296def8df4cdfbe9f169f8e37c443",
            "placeholder": "",
            "style": "IPY_MODEL_20e99a984bfc4c73b9a3967ea3892709",
            "value": "model.safetensors:100%"
          }
        },
        "f073e5a72fe0473caac7794a7cf9042b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ea981317c14935918a46a35a17792f",
            "max": 1333384464,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3db302b414404c10924bd6b436cea2d2",
            "value": 1333384464
          }
        },
        "1ffadd1e30c24836a7fecd5d1842d9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0c57ecb6014647a87611040c8149c5",
            "placeholder": "",
            "style": "IPY_MODEL_ced2813dabd04495bfd564c30411afff",
            "value": "1.33G/1.33G[00:12&lt;00:00,112MB/s]"
          }
        },
        "65b0e91d224d4607ba35250be0466184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccd296def8df4cdfbe9f169f8e37c443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e99a984bfc4c73b9a3967ea3892709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02ea981317c14935918a46a35a17792f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db302b414404c10924bd6b436cea2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea0c57ecb6014647a87611040c8149c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ced2813dabd04495bfd564c30411afff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d299a3c913d4192a681be29c8c8a948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_121e4aab9c31462b882841e20415c656",
              "IPY_MODEL_c83749e386c04a0596584d30022ef735",
              "IPY_MODEL_43517fa146d14e85bfea93d12b489261"
            ],
            "layout": "IPY_MODEL_8eda683780d74b83929c9061da6274dc"
          }
        },
        "121e4aab9c31462b882841e20415c656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22c19a01d7404a0aa23696a439bbfe28",
            "placeholder": "",
            "style": "IPY_MODEL_20964626779643a5a2c7af80a6f7555d",
            "value": "Loadingweights:100%"
          }
        },
        "c83749e386c04a0596584d30022ef735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_762bbf3b1eeb4c1b9edc03f0f986ce5c",
            "max": 478,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4406c79e5b104dbeaa98357c39b384b9",
            "value": 478
          }
        },
        "43517fa146d14e85bfea93d12b489261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cbe538b51d44f239ce9637dc48abdb7",
            "placeholder": "",
            "style": "IPY_MODEL_365cf321ca9048e98157a6179bc107b5",
            "value": "478/478[00:00&lt;00:00,671.67it/s,Materializingparam=encoder.layernorm.weight]"
          }
        },
        "8eda683780d74b83929c9061da6274dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22c19a01d7404a0aa23696a439bbfe28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20964626779643a5a2c7af80a6f7555d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "762bbf3b1eeb4c1b9edc03f0f986ce5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4406c79e5b104dbeaa98357c39b384b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cbe538b51d44f239ce9637dc48abdb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "365cf321ca9048e98157a6179bc107b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34d9473c0d7945f591549c8babbd15fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c74ab8bdad6b4ff3ac28cdc0807b42dd",
              "IPY_MODEL_c744e04333564357b000e70e576e0f5b",
              "IPY_MODEL_58355717cb5c473abc1f026ce3e9d8e4"
            ],
            "layout": "IPY_MODEL_74007dad360c4051a48e3a66ad64f1e0"
          }
        },
        "c74ab8bdad6b4ff3ac28cdc0807b42dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e820ec00e205492ea448f86aa0385201",
            "placeholder": "",
            "style": "IPY_MODEL_87bbc330f10d4a8b90d9655e081e404d",
            "value": "generation_config.json:100%"
          }
        },
        "c744e04333564357b000e70e576e0f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56ec3f2522ae486cb85985cd52476950",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28f32d2084cb4a2fb6b9c09d52c663ab",
            "value": 190
          }
        },
        "58355717cb5c473abc1f026ce3e9d8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a034704b78d433aa8f2cdd0e30c094b",
            "placeholder": "",
            "style": "IPY_MODEL_4a0022da3a6542f8adea36225476cbe4",
            "value": "190/190[00:00&lt;00:00,12.4kB/s]"
          }
        },
        "74007dad360c4051a48e3a66ad64f1e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e820ec00e205492ea448f86aa0385201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87bbc330f10d4a8b90d9655e081e404d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56ec3f2522ae486cb85985cd52476950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f32d2084cb4a2fb6b9c09d52c663ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a034704b78d433aa8f2cdd0e30c094b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a0022da3a6542f8adea36225476cbe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}